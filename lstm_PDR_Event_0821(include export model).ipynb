{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of UUIDs(patterns): 38212\n",
      "The average pattern length is : 240.59\n",
      "The average pattern length after eliminating the continuously events : 139.00\n",
      "The Quartile of pattern length is : 11.0\n",
      "The number of UUIDs(patterns) after elimiating the pattern which the length is less than the Quartile : 28636\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import random\n",
    "from tensorflow.contrib import rnn\n",
    "from dataHandle import DataHandler\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# open the file and read it into content\n",
    "with open('Trial2Buy01Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "uuid_pattern_list = [x.split('\\t')[2].strip('{''}').split(',') for x in content]  \n",
    "\n",
    "with open('Trial2Buy02Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "temp = [x.split('\\t')[2].strip('{''}').split(',') for x in content] \n",
    "uuid_pattern_list += temp\n",
    "\n",
    "with open('Trial2Buy03Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "temp = [x.split('\\t')[2].strip('{''}').split(',') for x in content] \n",
    "uuid_pattern_list += temp\n",
    "\n",
    "with open('Trial2Buy04Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "temp = [x.split('\\t')[2].strip('{''}').split(',') for x in content] \n",
    "uuid_pattern_list += temp\n",
    "\n",
    "with open('Trial2Buy05Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "temp = [x.split('\\t')[2].strip('{''}').split(',') for x in content] \n",
    "uuid_pattern_list += temp\n",
    "\n",
    "with open('Trial2Buy06Pattern','r') as f:\n",
    "    content = f.readlines()\n",
    "temp = [x.split('\\t')[2].strip('{''}').split(',') for x in content] \n",
    "uuid_pattern_list += temp\n",
    "\n",
    "print('Total number of UUIDs(patterns):', len(uuid_pattern_list))\n",
    "# calculate the average pattern length \n",
    "length = 0\n",
    "for pattern in uuid_pattern_list:\n",
    "    length += len(pattern)\n",
    "origin_avr_pattenr_length = \"{:.2f}\".format(length/len(uuid_pattern_list))\n",
    "\n",
    "print('The average pattern length is :',origin_avr_pattenr_length )\n",
    "\n",
    "# eliminate the continuously events in the pattern \n",
    "for i in range(len(uuid_pattern_list)):\n",
    "    temp = []\n",
    "    temp.append(uuid_pattern_list[i][0])\n",
    "    for j in range(len(uuid_pattern_list[i])):\n",
    "        if temp[len(temp)-1] == uuid_pattern_list[i][j]:\n",
    "            continue\n",
    "        temp.append(uuid_pattern_list[i][j])\n",
    "    uuid_pattern_list[i] = temp\n",
    "    \n",
    "# calculate the average pattern length after elimination \n",
    "length = 0\n",
    "for pattern in uuid_pattern_list:\n",
    "    length += len(pattern)\n",
    "elimation_avr_pattenr_length = \"{:.2f}\".format(length/len(uuid_pattern_list))\n",
    "\n",
    "print('The average pattern length after eliminating the continuously events :',elimation_avr_pattenr_length)\n",
    "\n",
    "\n",
    "# find the Quartile of the pattern length in all patterns \n",
    "number = []\n",
    "for pattern in uuid_pattern_list:\n",
    "    number.append(len(pattern))\n",
    "number.sort()\n",
    "per = np.percentile(number, 25)\n",
    "\n",
    "print (\"The Quartile of pattern length is :\",per)\n",
    "\n",
    "\n",
    "# eliminate the pattern if the pattern length is less than the quartile\n",
    "temp = []\n",
    "for pattern in uuid_pattern_list:\n",
    "    if len(pattern) <= per:\n",
    "        temp.append(pattern)#print (pattern)\n",
    "for pattern in temp:\n",
    "    uuid_pattern_list.remove(pattern)\n",
    "\n",
    "print (\"The number of UUIDs(patterns) after elimiating the pattern which the length is less than the Quartile :\",len(uuid_pattern_list))\n",
    "pattern_data = DataHandler(uuid_pattern_list[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(1,), dtype=int32)\n",
      "Max accuracy updated : \n",
      "Iter 0, Minibatch Loss= 5.145358, Training Accuracy= 0.03125\n",
      "Max accuracy updated : \n",
      "Iter 12800, Minibatch Loss= 3.219233, Training Accuracy= 0.23438\n",
      "Max accuracy updated : \n",
      "Iter 25600, Minibatch Loss= 2.729246, Training Accuracy= 0.28906\n",
      "Max accuracy updated : \n",
      "Iter 38400, Minibatch Loss= 2.162093, Training Accuracy= 0.47656\n",
      "Iter 51200, Minibatch Loss= 2.138229, Training Accuracy= 0.42969\n",
      "Iter 64000, Minibatch Loss= 2.258769, Training Accuracy= 0.45312\n",
      "Iter 76800, Minibatch Loss= 2.120676, Training Accuracy= 0.45312\n",
      "Max accuracy updated : \n",
      "Iter 89600, Minibatch Loss= 1.873186, Training Accuracy= 0.50781\n",
      "Iter 102400, Minibatch Loss= 1.900728, Training Accuracy= 0.50781\n",
      "Iter 115200, Minibatch Loss= 2.216349, Training Accuracy= 0.42188\n",
      "Max accuracy updated : \n",
      "Iter 128000, Minibatch Loss= 1.802467, Training Accuracy= 0.56250\n",
      "Iter 140800, Minibatch Loss= 1.968326, Training Accuracy= 0.44531\n",
      "Iter 153600, Minibatch Loss= 1.866689, Training Accuracy= 0.50000\n",
      "Iter 166400, Minibatch Loss= 1.843906, Training Accuracy= 0.51562\n",
      "Max accuracy updated : \n",
      "Iter 179200, Minibatch Loss= 1.626317, Training Accuracy= 0.59375\n",
      "Iter 192000, Minibatch Loss= 1.781151, Training Accuracy= 0.51562\n",
      "Iter 204800, Minibatch Loss= 1.856817, Training Accuracy= 0.47656\n",
      "Iter 217600, Minibatch Loss= 1.709524, Training Accuracy= 0.49219\n",
      "Iter 230400, Minibatch Loss= 2.147584, Training Accuracy= 0.40625\n",
      "Iter 243200, Minibatch Loss= 1.973682, Training Accuracy= 0.52344\n",
      "Iter 256000, Minibatch Loss= 2.094420, Training Accuracy= 0.45312\n",
      "Iter 268800, Minibatch Loss= 1.837447, Training Accuracy= 0.53906\n",
      "Iter 281600, Minibatch Loss= 1.828016, Training Accuracy= 0.46875\n",
      "Iter 294400, Minibatch Loss= 1.694110, Training Accuracy= 0.53125\n",
      "Iter 307200, Minibatch Loss= 1.690102, Training Accuracy= 0.47656\n",
      "Iter 320000, Minibatch Loss= 1.912009, Training Accuracy= 0.46094\n",
      "Iter 332800, Minibatch Loss= 1.822780, Training Accuracy= 0.52344\n",
      "Iter 345600, Minibatch Loss= 2.140769, Training Accuracy= 0.46875\n",
      "Iter 358400, Minibatch Loss= 1.777941, Training Accuracy= 0.56250\n",
      "Iter 371200, Minibatch Loss= 1.769646, Training Accuracy= 0.49219\n",
      "Iter 384000, Minibatch Loss= 2.105462, Training Accuracy= 0.44531\n",
      "Iter 396800, Minibatch Loss= 1.809712, Training Accuracy= 0.46094\n",
      "Iter 409600, Minibatch Loss= 1.924799, Training Accuracy= 0.45312\n",
      "Iter 422400, Minibatch Loss= 1.677180, Training Accuracy= 0.58594\n",
      "Iter 435200, Minibatch Loss= 1.793934, Training Accuracy= 0.53125\n",
      "Max accuracy updated : \n",
      "Iter 448000, Minibatch Loss= 1.607801, Training Accuracy= 0.62500\n",
      "Iter 460800, Minibatch Loss= 1.985218, Training Accuracy= 0.49219\n",
      "Iter 473600, Minibatch Loss= 1.852560, Training Accuracy= 0.53125\n",
      "Iter 486400, Minibatch Loss= 1.782068, Training Accuracy= 0.48438\n",
      "Iter 499200, Minibatch Loss= 1.756967, Training Accuracy= 0.51562\n",
      "Iter 512000, Minibatch Loss= 1.753240, Training Accuracy= 0.50000\n",
      "Iter 524800, Minibatch Loss= 1.559964, Training Accuracy= 0.58594\n",
      "Iter 537600, Minibatch Loss= 1.690856, Training Accuracy= 0.49219\n",
      "Iter 550400, Minibatch Loss= 2.039078, Training Accuracy= 0.43750\n",
      "Iter 563200, Minibatch Loss= 1.570698, Training Accuracy= 0.57031\n",
      "Iter 576000, Minibatch Loss= 2.179330, Training Accuracy= 0.47656\n",
      "Iter 588800, Minibatch Loss= 1.723733, Training Accuracy= 0.50781\n",
      "Iter 601600, Minibatch Loss= 1.879148, Training Accuracy= 0.46094\n",
      "Iter 614400, Minibatch Loss= 1.901753, Training Accuracy= 0.50000\n",
      "Iter 627200, Minibatch Loss= 1.598297, Training Accuracy= 0.53906\n",
      "Iter 640000, Minibatch Loss= 1.654107, Training Accuracy= 0.53906\n",
      "Iter 652800, Minibatch Loss= 1.623953, Training Accuracy= 0.48438\n",
      "Iter 665600, Minibatch Loss= 1.731508, Training Accuracy= 0.50781\n",
      "Iter 678400, Minibatch Loss= 1.644507, Training Accuracy= 0.53906\n",
      "Iter 691200, Minibatch Loss= 1.901437, Training Accuracy= 0.46094\n",
      "Iter 704000, Minibatch Loss= 1.654605, Training Accuracy= 0.53906\n",
      "Iter 716800, Minibatch Loss= 1.740750, Training Accuracy= 0.50000\n",
      "Iter 729600, Minibatch Loss= 1.765674, Training Accuracy= 0.51562\n",
      "Max accuracy updated : \n",
      "Iter 742400, Minibatch Loss= 1.470242, Training Accuracy= 0.64062\n",
      "Iter 755200, Minibatch Loss= 1.601204, Training Accuracy= 0.53125\n",
      "Iter 768000, Minibatch Loss= 1.725602, Training Accuracy= 0.50781\n",
      "Iter 780800, Minibatch Loss= 1.697168, Training Accuracy= 0.53125\n",
      "Iter 793600, Minibatch Loss= 1.678094, Training Accuracy= 0.53125\n",
      "Iter 806400, Minibatch Loss= 1.916538, Training Accuracy= 0.48438\n",
      "Iter 819200, Minibatch Loss= 1.747387, Training Accuracy= 0.50000\n",
      "Iter 832000, Minibatch Loss= 1.992588, Training Accuracy= 0.43750\n",
      "Iter 844800, Minibatch Loss= 1.772080, Training Accuracy= 0.51562\n",
      "Iter 857600, Minibatch Loss= 1.927925, Training Accuracy= 0.48438\n",
      "Iter 870400, Minibatch Loss= 1.794075, Training Accuracy= 0.53125\n",
      "Iter 883200, Minibatch Loss= 1.706060, Training Accuracy= 0.57031\n",
      "Iter 896000, Minibatch Loss= 1.688316, Training Accuracy= 0.58594\n",
      "Iter 908800, Minibatch Loss= 1.939705, Training Accuracy= 0.47656\n",
      "Iter 921600, Minibatch Loss= 2.011938, Training Accuracy= 0.46875\n",
      "Iter 934400, Minibatch Loss= 1.870297, Training Accuracy= 0.47656\n",
      "Iter 947200, Minibatch Loss= 1.894667, Training Accuracy= 0.42969\n",
      "Iter 960000, Minibatch Loss= 1.900527, Training Accuracy= 0.49219\n",
      "Iter 972800, Minibatch Loss= 1.666397, Training Accuracy= 0.55469\n",
      "Iter 985600, Minibatch Loss= 2.018593, Training Accuracy= 0.45312\n",
      "Iter 998400, Minibatch Loss= 1.635913, Training Accuracy= 0.50781\n",
      "Iter 1011200, Minibatch Loss= 1.736607, Training Accuracy= 0.52344\n",
      "Iter 1024000, Minibatch Loss= 1.730909, Training Accuracy= 0.49219\n",
      "Iter 1036800, Minibatch Loss= 1.484609, Training Accuracy= 0.58594\n",
      "Iter 1049600, Minibatch Loss= 1.361050, Training Accuracy= 0.57812\n",
      "Iter 1062400, Minibatch Loss= 1.522782, Training Accuracy= 0.59375\n",
      "Iter 1075200, Minibatch Loss= 1.609339, Training Accuracy= 0.59375\n",
      "Iter 1088000, Minibatch Loss= 1.661113, Training Accuracy= 0.50000\n",
      "Iter 1100800, Minibatch Loss= 2.083548, Training Accuracy= 0.42188\n",
      "Iter 1113600, Minibatch Loss= 1.637078, Training Accuracy= 0.50000\n",
      "Iter 1126400, Minibatch Loss= 2.025354, Training Accuracy= 0.44531\n",
      "Iter 1139200, Minibatch Loss= 1.772330, Training Accuracy= 0.52344\n",
      "Iter 1152000, Minibatch Loss= 1.449723, Training Accuracy= 0.51562\n",
      "Iter 1164800, Minibatch Loss= 1.564526, Training Accuracy= 0.55469\n",
      "Iter 1177600, Minibatch Loss= 1.926785, Training Accuracy= 0.50781\n",
      "Iter 1190400, Minibatch Loss= 1.931574, Training Accuracy= 0.50781\n",
      "Iter 1203200, Minibatch Loss= 1.833200, Training Accuracy= 0.50000\n",
      "Iter 1216000, Minibatch Loss= 1.769175, Training Accuracy= 0.50781\n",
      "Iter 1228800, Minibatch Loss= 1.592522, Training Accuracy= 0.57031\n",
      "Iter 1241600, Minibatch Loss= 1.675540, Training Accuracy= 0.49219\n",
      "Iter 1254400, Minibatch Loss= 1.639939, Training Accuracy= 0.52344\n",
      "Iter 1267200, Minibatch Loss= 1.700574, Training Accuracy= 0.52344\n",
      "Iter 1280000, Minibatch Loss= 1.708219, Training Accuracy= 0.54688\n",
      "Iter 1292800, Minibatch Loss= 1.718904, Training Accuracy= 0.50000\n",
      "Iter 1305600, Minibatch Loss= 1.601405, Training Accuracy= 0.57031\n",
      "Iter 1318400, Minibatch Loss= 1.467287, Training Accuracy= 0.54688\n",
      "Iter 1331200, Minibatch Loss= 2.102329, Training Accuracy= 0.39062\n",
      "Iter 1344000, Minibatch Loss= 1.875900, Training Accuracy= 0.50000\n",
      "Iter 1356800, Minibatch Loss= 1.814646, Training Accuracy= 0.45312\n",
      "Iter 1369600, Minibatch Loss= 1.539709, Training Accuracy= 0.58594\n",
      "Iter 1382400, Minibatch Loss= 1.805908, Training Accuracy= 0.42969\n",
      "Iter 1395200, Minibatch Loss= 1.524508, Training Accuracy= 0.55469\n",
      "Iter 1408000, Minibatch Loss= 1.627701, Training Accuracy= 0.59375\n",
      "Iter 1420800, Minibatch Loss= 1.738984, Training Accuracy= 0.53125\n",
      "Iter 1433600, Minibatch Loss= 1.754152, Training Accuracy= 0.48438\n",
      "Iter 1446400, Minibatch Loss= 1.902993, Training Accuracy= 0.48438\n",
      "Iter 1459200, Minibatch Loss= 1.700798, Training Accuracy= 0.49219\n",
      "Iter 1472000, Minibatch Loss= 1.770469, Training Accuracy= 0.54688\n",
      "Iter 1484800, Minibatch Loss= 1.503788, Training Accuracy= 0.56250\n",
      "Iter 1497600, Minibatch Loss= 1.739672, Training Accuracy= 0.53125\n",
      "Iter 1510400, Minibatch Loss= 1.599953, Training Accuracy= 0.56250\n",
      "Iter 1523200, Minibatch Loss= 1.571209, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1536000, Minibatch Loss= 1.704901, Training Accuracy= 0.54688\n",
      "Iter 1548800, Minibatch Loss= 1.572839, Training Accuracy= 0.51562\n",
      "Iter 1561600, Minibatch Loss= 1.918414, Training Accuracy= 0.41406\n",
      "Iter 1574400, Minibatch Loss= 1.644549, Training Accuracy= 0.53125\n",
      "Iter 1587200, Minibatch Loss= 1.568223, Training Accuracy= 0.59375\n",
      "Iter 1600000, Minibatch Loss= 1.797582, Training Accuracy= 0.50000\n",
      "Iter 1612800, Minibatch Loss= 1.865628, Training Accuracy= 0.47656\n",
      "Iter 1625600, Minibatch Loss= 1.698554, Training Accuracy= 0.47656\n",
      "Iter 1638400, Minibatch Loss= 1.713824, Training Accuracy= 0.54688\n",
      "Iter 1651200, Minibatch Loss= 1.752671, Training Accuracy= 0.48438\n",
      "Iter 1664000, Minibatch Loss= 1.672084, Training Accuracy= 0.55469\n",
      "Iter 1676800, Minibatch Loss= 1.846859, Training Accuracy= 0.47656\n",
      "Iter 1689600, Minibatch Loss= 1.509247, Training Accuracy= 0.52344\n",
      "Iter 1702400, Minibatch Loss= 1.717191, Training Accuracy= 0.50000\n",
      "Iter 1715200, Minibatch Loss= 1.998105, Training Accuracy= 0.47656\n",
      "Iter 1728000, Minibatch Loss= 1.756684, Training Accuracy= 0.55469\n",
      "Iter 1740800, Minibatch Loss= 1.684365, Training Accuracy= 0.57031\n",
      "Iter 1753600, Minibatch Loss= 1.805293, Training Accuracy= 0.46875\n",
      "Iter 1766400, Minibatch Loss= 2.042358, Training Accuracy= 0.40625\n",
      "Iter 1779200, Minibatch Loss= 1.740877, Training Accuracy= 0.52344\n",
      "Iter 1792000, Minibatch Loss= 1.539022, Training Accuracy= 0.55469\n",
      "Iter 1804800, Minibatch Loss= 1.578686, Training Accuracy= 0.51562\n",
      "Iter 1817600, Minibatch Loss= 1.390086, Training Accuracy= 0.58594\n",
      "Iter 1830400, Minibatch Loss= 1.894755, Training Accuracy= 0.45312\n",
      "Iter 1843200, Minibatch Loss= 1.865726, Training Accuracy= 0.49219\n",
      "Iter 1856000, Minibatch Loss= 2.074170, Training Accuracy= 0.42969\n",
      "Iter 1868800, Minibatch Loss= 1.678843, Training Accuracy= 0.52344\n",
      "Iter 1881600, Minibatch Loss= 1.803531, Training Accuracy= 0.45312\n",
      "Iter 1894400, Minibatch Loss= 1.684733, Training Accuracy= 0.53125\n",
      "Iter 1907200, Minibatch Loss= 1.425653, Training Accuracy= 0.62500\n",
      "Iter 1920000, Minibatch Loss= 1.899023, Training Accuracy= 0.47656\n",
      "Iter 1932800, Minibatch Loss= 1.994304, Training Accuracy= 0.46094\n",
      "Iter 1945600, Minibatch Loss= 1.690414, Training Accuracy= 0.50000\n",
      "Iter 1958400, Minibatch Loss= 1.794765, Training Accuracy= 0.49219\n",
      "Iter 1971200, Minibatch Loss= 1.813405, Training Accuracy= 0.44531\n",
      "Iter 1984000, Minibatch Loss= 1.652922, Training Accuracy= 0.54688\n",
      "Iter 1996800, Minibatch Loss= 1.782227, Training Accuracy= 0.51562\n",
      "Iter 2009600, Minibatch Loss= 1.708572, Training Accuracy= 0.50000\n",
      "Iter 2022400, Minibatch Loss= 1.882242, Training Accuracy= 0.46875\n",
      "Iter 2035200, Minibatch Loss= 1.342431, Training Accuracy= 0.59375\n",
      "Iter 2048000, Minibatch Loss= 1.759286, Training Accuracy= 0.53906\n",
      "Iter 2060800, Minibatch Loss= 1.596979, Training Accuracy= 0.58594\n",
      "Iter 2073600, Minibatch Loss= 1.656241, Training Accuracy= 0.54688\n",
      "Iter 2086400, Minibatch Loss= 2.074765, Training Accuracy= 0.46875\n",
      "Iter 2099200, Minibatch Loss= 1.573501, Training Accuracy= 0.54688\n",
      "Iter 2112000, Minibatch Loss= 1.642032, Training Accuracy= 0.55469\n",
      "Iter 2124800, Minibatch Loss= 1.879239, Training Accuracy= 0.46875\n",
      "Iter 2137600, Minibatch Loss= 1.769830, Training Accuracy= 0.48438\n",
      "Iter 2150400, Minibatch Loss= 1.816663, Training Accuracy= 0.46094\n",
      "Iter 2163200, Minibatch Loss= 1.614671, Training Accuracy= 0.53125\n",
      "Iter 2176000, Minibatch Loss= 1.868126, Training Accuracy= 0.53125\n",
      "Iter 2188800, Minibatch Loss= 1.715761, Training Accuracy= 0.51562\n",
      "Iter 2201600, Minibatch Loss= 1.894638, Training Accuracy= 0.50000\n",
      "Iter 2214400, Minibatch Loss= 1.959621, Training Accuracy= 0.50781\n",
      "Iter 2227200, Minibatch Loss= 1.639762, Training Accuracy= 0.53906\n",
      "Iter 2240000, Minibatch Loss= 1.593803, Training Accuracy= 0.54688\n",
      "Iter 2252800, Minibatch Loss= 1.672688, Training Accuracy= 0.52344\n",
      "Iter 2265600, Minibatch Loss= 1.484881, Training Accuracy= 0.61719\n",
      "Iter 2278400, Minibatch Loss= 1.758199, Training Accuracy= 0.52344\n",
      "Iter 2291200, Minibatch Loss= 1.728195, Training Accuracy= 0.51562\n",
      "Iter 2304000, Minibatch Loss= 2.009713, Training Accuracy= 0.45312\n",
      "Iter 2316800, Minibatch Loss= 1.848893, Training Accuracy= 0.50000\n",
      "Iter 2329600, Minibatch Loss= 1.875618, Training Accuracy= 0.51562\n",
      "Iter 2342400, Minibatch Loss= 1.853464, Training Accuracy= 0.53125\n",
      "Iter 2355200, Minibatch Loss= 1.667976, Training Accuracy= 0.52344\n",
      "Iter 2368000, Minibatch Loss= 1.925836, Training Accuracy= 0.50781\n",
      "Iter 2380800, Minibatch Loss= 1.904538, Training Accuracy= 0.44531\n",
      "Iter 2393600, Minibatch Loss= 1.719527, Training Accuracy= 0.46094\n",
      "Iter 2406400, Minibatch Loss= 1.769701, Training Accuracy= 0.46875\n",
      "Iter 2419200, Minibatch Loss= 1.724237, Training Accuracy= 0.52344\n",
      "Iter 2432000, Minibatch Loss= 1.880391, Training Accuracy= 0.46875\n",
      "Iter 2444800, Minibatch Loss= 1.444073, Training Accuracy= 0.52344\n",
      "Iter 2457600, Minibatch Loss= 1.697904, Training Accuracy= 0.51562\n",
      "Iter 2470400, Minibatch Loss= 1.773972, Training Accuracy= 0.56250\n",
      "Iter 2483200, Minibatch Loss= 1.755206, Training Accuracy= 0.50781\n",
      "Iter 2496000, Minibatch Loss= 1.916612, Training Accuracy= 0.45312\n",
      "Iter 2508800, Minibatch Loss= 1.638088, Training Accuracy= 0.60156\n",
      "Iter 2521600, Minibatch Loss= 1.755569, Training Accuracy= 0.57812\n",
      "Iter 2534400, Minibatch Loss= 1.591513, Training Accuracy= 0.55469\n",
      "Iter 2547200, Minibatch Loss= 1.603984, Training Accuracy= 0.51562\n",
      "Iter 2560000, Minibatch Loss= 1.646471, Training Accuracy= 0.51562\n",
      "Iter 2572800, Minibatch Loss= 1.724261, Training Accuracy= 0.51562\n",
      "Iter 2585600, Minibatch Loss= 1.699419, Training Accuracy= 0.53906\n",
      "Iter 2598400, Minibatch Loss= 1.396486, Training Accuracy= 0.61719\n",
      "Iter 2611200, Minibatch Loss= 1.836413, Training Accuracy= 0.46875\n",
      "Iter 2624000, Minibatch Loss= 1.657531, Training Accuracy= 0.53125\n",
      "Iter 2636800, Minibatch Loss= 1.830777, Training Accuracy= 0.46094\n",
      "Iter 2649600, Minibatch Loss= 1.532417, Training Accuracy= 0.57812\n",
      "Iter 2662400, Minibatch Loss= 1.599847, Training Accuracy= 0.58594\n",
      "Iter 2675200, Minibatch Loss= 1.687180, Training Accuracy= 0.50000\n",
      "Iter 2688000, Minibatch Loss= 1.694964, Training Accuracy= 0.52344\n",
      "Iter 2700800, Minibatch Loss= 1.734250, Training Accuracy= 0.55469\n",
      "Iter 2713600, Minibatch Loss= 1.603952, Training Accuracy= 0.47656\n",
      "Iter 2726400, Minibatch Loss= 2.163036, Training Accuracy= 0.41406\n",
      "Iter 2739200, Minibatch Loss= 2.001569, Training Accuracy= 0.40625\n",
      "Iter 2752000, Minibatch Loss= 1.914232, Training Accuracy= 0.48438\n",
      "Iter 2764800, Minibatch Loss= 1.862076, Training Accuracy= 0.50000\n",
      "Iter 2777600, Minibatch Loss= 1.481140, Training Accuracy= 0.50000\n",
      "Iter 2790400, Minibatch Loss= 1.705173, Training Accuracy= 0.50000\n",
      "Iter 2803200, Minibatch Loss= 1.670246, Training Accuracy= 0.53125\n",
      "Iter 2816000, Minibatch Loss= 1.599924, Training Accuracy= 0.52344\n",
      "Iter 2828800, Minibatch Loss= 1.923619, Training Accuracy= 0.46875\n",
      "Iter 2841600, Minibatch Loss= 2.080840, Training Accuracy= 0.39062\n",
      "Iter 2854400, Minibatch Loss= 1.590518, Training Accuracy= 0.57812\n",
      "Iter 2867200, Minibatch Loss= 1.712626, Training Accuracy= 0.53125\n",
      "Iter 2880000, Minibatch Loss= 1.666536, Training Accuracy= 0.52344\n",
      "Iter 2892800, Minibatch Loss= 1.750739, Training Accuracy= 0.50000\n",
      "Iter 2905600, Minibatch Loss= 1.663792, Training Accuracy= 0.52344\n",
      "Iter 2918400, Minibatch Loss= 1.749058, Training Accuracy= 0.52344\n",
      "Iter 2931200, Minibatch Loss= 1.666386, Training Accuracy= 0.53125\n",
      "Iter 2944000, Minibatch Loss= 1.775256, Training Accuracy= 0.48438\n",
      "Iter 2956800, Minibatch Loss= 1.898343, Training Accuracy= 0.45312\n",
      "Iter 2969600, Minibatch Loss= 1.583781, Training Accuracy= 0.50000\n",
      "Iter 2982400, Minibatch Loss= 1.502596, Training Accuracy= 0.59375\n",
      "Iter 2995200, Minibatch Loss= 1.607016, Training Accuracy= 0.55469\n",
      "Iter 3008000, Minibatch Loss= 1.771445, Training Accuracy= 0.49219\n",
      "Iter 3020800, Minibatch Loss= 1.718311, Training Accuracy= 0.52344\n",
      "Iter 3033600, Minibatch Loss= 1.431164, Training Accuracy= 0.60156\n",
      "Iter 3046400, Minibatch Loss= 1.597998, Training Accuracy= 0.55469\n",
      "Iter 3059200, Minibatch Loss= 1.714295, Training Accuracy= 0.57031\n",
      "Iter 3072000, Minibatch Loss= 1.953069, Training Accuracy= 0.44531\n",
      "Iter 3084800, Minibatch Loss= 1.843652, Training Accuracy= 0.49219\n",
      "Iter 3097600, Minibatch Loss= 1.814972, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3110400, Minibatch Loss= 1.810379, Training Accuracy= 0.49219\n",
      "Iter 3123200, Minibatch Loss= 1.648998, Training Accuracy= 0.53906\n",
      "Iter 3136000, Minibatch Loss= 1.657631, Training Accuracy= 0.52344\n",
      "Iter 3148800, Minibatch Loss= 1.733427, Training Accuracy= 0.51562\n",
      "Iter 3161600, Minibatch Loss= 1.905890, Training Accuracy= 0.47656\n",
      "Iter 3174400, Minibatch Loss= 1.637649, Training Accuracy= 0.55469\n",
      "Iter 3187200, Minibatch Loss= 1.703553, Training Accuracy= 0.53125\n",
      "Iter 3200000, Minibatch Loss= 1.819548, Training Accuracy= 0.49219\n",
      "Iter 3212800, Minibatch Loss= 1.670913, Training Accuracy= 0.53906\n",
      "Iter 3225600, Minibatch Loss= 1.893682, Training Accuracy= 0.48438\n",
      "Iter 3238400, Minibatch Loss= 1.772326, Training Accuracy= 0.53906\n",
      "Iter 3251200, Minibatch Loss= 1.662794, Training Accuracy= 0.52344\n",
      "Iter 3264000, Minibatch Loss= 1.429763, Training Accuracy= 0.58594\n",
      "Iter 3276800, Minibatch Loss= 1.794670, Training Accuracy= 0.50000\n",
      "Iter 3289600, Minibatch Loss= 1.678242, Training Accuracy= 0.50781\n",
      "Iter 3302400, Minibatch Loss= 2.146930, Training Accuracy= 0.37500\n",
      "Iter 3315200, Minibatch Loss= 1.716221, Training Accuracy= 0.50000\n",
      "Iter 3328000, Minibatch Loss= 1.924469, Training Accuracy= 0.43750\n",
      "Iter 3340800, Minibatch Loss= 1.623434, Training Accuracy= 0.53906\n",
      "Iter 3353600, Minibatch Loss= 1.776128, Training Accuracy= 0.56250\n",
      "Iter 3366400, Minibatch Loss= 1.749552, Training Accuracy= 0.50781\n",
      "Iter 3379200, Minibatch Loss= 1.382264, Training Accuracy= 0.60938\n",
      "Iter 3392000, Minibatch Loss= 2.155484, Training Accuracy= 0.42188\n",
      "Iter 3404800, Minibatch Loss= 1.639785, Training Accuracy= 0.53125\n",
      "Iter 3417600, Minibatch Loss= 1.524052, Training Accuracy= 0.53906\n",
      "Iter 3430400, Minibatch Loss= 1.500211, Training Accuracy= 0.60938\n",
      "Iter 3443200, Minibatch Loss= 1.831802, Training Accuracy= 0.50000\n",
      "Iter 3456000, Minibatch Loss= 1.846226, Training Accuracy= 0.56250\n",
      "Iter 3468800, Minibatch Loss= 1.770725, Training Accuracy= 0.51562\n",
      "Iter 3481600, Minibatch Loss= 1.555050, Training Accuracy= 0.57031\n",
      "Iter 3494400, Minibatch Loss= 1.813148, Training Accuracy= 0.51562\n",
      "Iter 3507200, Minibatch Loss= 1.746445, Training Accuracy= 0.50000\n",
      "Iter 3520000, Minibatch Loss= 1.737185, Training Accuracy= 0.50781\n",
      "Iter 3532800, Minibatch Loss= 1.857859, Training Accuracy= 0.50000\n",
      "Iter 3545600, Minibatch Loss= 1.830262, Training Accuracy= 0.50000\n",
      "Iter 3558400, Minibatch Loss= 1.671493, Training Accuracy= 0.52344\n",
      "Iter 3571200, Minibatch Loss= 1.644107, Training Accuracy= 0.58594\n",
      "Iter 3584000, Minibatch Loss= 1.784272, Training Accuracy= 0.50781\n",
      "Iter 3596800, Minibatch Loss= 1.893251, Training Accuracy= 0.51562\n",
      "Iter 3609600, Minibatch Loss= 1.746472, Training Accuracy= 0.52344\n",
      "Iter 3622400, Minibatch Loss= 1.814434, Training Accuracy= 0.47656\n",
      "Iter 3635200, Minibatch Loss= 1.741638, Training Accuracy= 0.50000\n",
      "Iter 3648000, Minibatch Loss= 1.838048, Training Accuracy= 0.44531\n",
      "Iter 3660800, Minibatch Loss= 1.645711, Training Accuracy= 0.57031\n",
      "Iter 3673600, Minibatch Loss= 1.559101, Training Accuracy= 0.56250\n",
      "Iter 3686400, Minibatch Loss= 1.831008, Training Accuracy= 0.48438\n",
      "Iter 3699200, Minibatch Loss= 1.674665, Training Accuracy= 0.46875\n",
      "Iter 3712000, Minibatch Loss= 1.731888, Training Accuracy= 0.53125\n",
      "Iter 3724800, Minibatch Loss= 1.678933, Training Accuracy= 0.51562\n",
      "Iter 3737600, Minibatch Loss= 1.993720, Training Accuracy= 0.43750\n",
      "Iter 3750400, Minibatch Loss= 1.273685, Training Accuracy= 0.60156\n",
      "Iter 3763200, Minibatch Loss= 1.808639, Training Accuracy= 0.52344\n",
      "Iter 3776000, Minibatch Loss= 1.593913, Training Accuracy= 0.56250\n",
      "Iter 3788800, Minibatch Loss= 1.677362, Training Accuracy= 0.51562\n",
      "Iter 3801600, Minibatch Loss= 1.624687, Training Accuracy= 0.56250\n",
      "Iter 3814400, Minibatch Loss= 1.584443, Training Accuracy= 0.58594\n",
      "Iter 3827200, Minibatch Loss= 1.925262, Training Accuracy= 0.46875\n",
      "Iter 3840000, Minibatch Loss= 1.916349, Training Accuracy= 0.50000\n",
      "Iter 3852800, Minibatch Loss= 1.874176, Training Accuracy= 0.46094\n",
      "Iter 3865600, Minibatch Loss= 1.762774, Training Accuracy= 0.51562\n",
      "Iter 3878400, Minibatch Loss= 1.692816, Training Accuracy= 0.48438\n",
      "Iter 3891200, Minibatch Loss= 1.431095, Training Accuracy= 0.56250\n",
      "Iter 3904000, Minibatch Loss= 1.552799, Training Accuracy= 0.56250\n",
      "Iter 3916800, Minibatch Loss= 1.575956, Training Accuracy= 0.56250\n",
      "Iter 3929600, Minibatch Loss= 1.322914, Training Accuracy= 0.64062\n",
      "Iter 3942400, Minibatch Loss= 1.903160, Training Accuracy= 0.43750\n",
      "Iter 3955200, Minibatch Loss= 1.649775, Training Accuracy= 0.53125\n",
      "Iter 3968000, Minibatch Loss= 1.682574, Training Accuracy= 0.51562\n",
      "Iter 3980800, Minibatch Loss= 1.549870, Training Accuracy= 0.57812\n",
      "Iter 3993600, Minibatch Loss= 1.580729, Training Accuracy= 0.54688\n",
      "Iter 4006400, Minibatch Loss= 1.602509, Training Accuracy= 0.56250\n",
      "Iter 4019200, Minibatch Loss= 1.716542, Training Accuracy= 0.53125\n",
      "Iter 4032000, Minibatch Loss= 1.794320, Training Accuracy= 0.50000\n",
      "Iter 4044800, Minibatch Loss= 1.462202, Training Accuracy= 0.57812\n",
      "Iter 4057600, Minibatch Loss= 1.661804, Training Accuracy= 0.48438\n",
      "Iter 4070400, Minibatch Loss= 1.664206, Training Accuracy= 0.49219\n",
      "Iter 4083200, Minibatch Loss= 1.512823, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXe8HVW593/Pnt1Oz0ly0hMSSCgJEEpEVJoKGDoqKnjR\na7vo+14uKOorNlTUq1e9drzC9So2+kUBDUWkIy1AEkhIIKSQnPScXnaZmfX+MbPWXjN7Zpdz9pyS\n83w/Hz5k7zN7Zk1bT38WCSHAMAzDMAAQG+0BMAzDMGMHFgoMwzCMgoUCwzAMo2ChwDAMwyhYKDAM\nwzAKFgoMwzCMgoUCc0BCRAYR9RHRvFpuyzAHOiwUmDGBOynL/2wiGtQ+/1O1+xNCWEKIRiHEG7Xc\ntlqI6FtElHfPo4uIniSiN9f6OAxTK1goMGMCd1JuFEI0AngDwHnad3/0b09E8ZEf5ZD5o3te0wA8\nA+B/gzYaZ+fEHKCwUGDGBa7GfSsR3UxEvQAuJaK3ENHTrga+k4h+SkQJd/s4EQkimu9+/oP793uJ\nqJeIniKiBdVu6/79LCJ6lYi6iehnrvb/kXLnIITIAfgtgNlENImIPkFEj7nH6gDwFSKKEdE1RLSV\niPYQ0Y1E1Kwd+xT3nLuJaBsRfcj9Pk1EP3S/201EvyCitPu3aUS0wr1OHUT0mLa/LxHRDiLqIaL1\nRHTacO4TM/5hocCMJ94N4CYALQBuBWACuBLAVABvA7AcwCdL/P6DAL4KYDIca+Sb1W5LRNMA3Abg\n8+5xNwM4oZLBE1EKwEcAbBFCdLlfvxXAKwDaAPwHgE8AuBTAaQAOAdAK4Cfu7xcAWAHghwCmADgW\nwEvufr4PYAGAowEsAjAfwJfdv30ewCb3GDMAfMXd3xI41+s4IUQzgLPcc2UmMCwUmPHEE0KIe4QQ\nthBiUAjxnBDiGSGEKYTYBOAGAKeW+P0dQoiVQog8gD8COGYI254LYJUQ4i73bz8CsK/MuD9IRF0A\ntgE4Co5wk7whhPgvN64xCOCfAPxACLFZCNEL4Evu72NwhMW9Qojb3HPeJ4RY5f7tXwB8WgjRKYTo\nAfAdABe7x8gDmAVgnhAiJ4SQloIJIA1gCRHF3WNuKnMuzAEOCwVmPLFN/0BEhxPRX4loFxH1ALgW\njvYexi7t3wMAGoew7Sx9HMLpKLm9zLhvEkJMEkJME0KcLoRYpf1tm2/bWQC2ap+3AkjC0fLnAng9\nYP8zAKQArHZdRF0A/gInhgEA33X383ciep2IPu+OfQOAz8K5bntc19yMMufCHOCwUGDGE/6WvtcD\neBnAQtf9cQ0AingMOwHMkR+IiADMHsb+/Oe0A8BB2ud5AHIA9sIRIIcE7GO3u81hrvCZJIRoEUK0\nAIAQokcI8RkhxHwAFwL4AhGd6v7tD0KIt8FxPRlwLAxmAsNCgRnPNAHoBtBPREegdDyhVvwFwHFE\ndJ6bLXQlHC2+VtwM4Coimk9ETQC+DeBmIYQN4A8AlhPRe93g+FQiWiqEsAD8CsCPiaiNHOYQ0ZkA\n4I71EFeAdQOwANhEdAQRvd2NdQy6/9k1PBdmHMJCgRnPfBbAPwPohWM13Br1AYUQuwF8AE6wdz8c\nzf1FANkaHeK/4ZzH43CCw71wBA+EEJsBnAfgCwA6ALwAJ0YBONdiK4Bn4Uz8D8AJOAPAYQAeAtAH\n4EkAPxFCPA7H5fQ9ODGRXXCC2jI4zUxQiBfZYZihQ0QGHJfPRe5EyzDjGrYUGKZKiGi5W2eQgpO2\nmoejoTPMuIeFAsNUz0lwXDt7AbwLwLuFELVyHzHMqMLuI4ZhGEbBlgLDMAyjGHcNuKZOnSrmz58/\n2sNgGIYZVzz//PP7hBBl06fHnVCYP38+Vq5cOdrDYBiGGVcQ0dbyW7H7iGEYhtFgocAwDMMoWCgw\nDMMwChYKDMMwjIKFAsMwDKNgocAwDMMoWCgwDMMwChYKBwh/frEdfVlztIfBMEyFbO8cwMPr94z2\nMIpgoXAAsKNrEJ++dRVWvLRztIfCMEyFLP/x4/jojc+N9jCKYKFwAJDJW57/Mwwz9hmrlj0LhQOA\nvOV0us2ZvJIiwzDDg4XCAUDecoRBloUCw4w7xtryBSwURpjHXt2L3ky+pvvMuUJBCgemdpiWjfvX\n7hpzLy5z4GDZY+vZYqEwgvRk8vjn3zyLP73YXtP95l0Lgd1HtefJ1/fjk79/Hut29oz2UJgDFJOF\nwsRlMGdBCGAgV9uAMMcUoqMv4wQDB2t8zxhGwpbCBCabd908NZ68pdsox+6jmpM1HWEgBW+U3LWq\nHZ+9bXWkx/jCHWvw9bvXRnoMpjrYUpjAFCaY2k7eUhiwpVB7ZPDetKO/tk9v2o8H1u6K9Bi3rtyG\nG/+xJdJjMNVhs1CYuMgJJl/jhyDPQiEysm7thzkClkI2b3MGWY3o7M9hw65e9XlbxwC2dQyM4ojC\nmVCWAhEtJ6INRLSRiK4O2eb9RLSOiNYS0U1Rjme0UZZCRO6jLLuPao4S5CNwbbOmjZxljznNcTxy\nzk8fx7t+/Jj6/KU/vYSv/PnlURxROGMtphDZGs1EZAC4DsAZALYDeI6I7hZCrNO2WQTgiwDeJoTo\nJKJpUY1nLKBiCjWeYPImB5qjouA+GgFLwVUacpaNdMyI/HgHMju6M57PHf05JONj0zFijbF05yiv\n0gkANgohNgkhcgBuAXCBb5t/AXCdEKITAIQQY687VA3JSEuhxhMM1ylER1RxoOBjuRZffnjHevGN\nTlx+0wtjTgMFHDfOx258Dv0j3OJhMGdFqjR98c41uPOF7RVvr98bawRck9UQpVCYDWCb9nm7+53O\noQAOJaIniehpIloetCMiuoyIVhLRyr1790Y03OiJKvsox3UKkVGw7kYmpgAUBNFQeXpTB/6yZid2\ndA16vh8LBXgrt3bgofV7sHFP34gedyBioXDzs9twVRWZY3qfspFIYqiG0ban4gAWATgNwCUA/puI\nJvk3EkLcIIRYJoRY1tbWNqID3Lint2ZaYlT+6agDzbYt8OTGfXh2c0ck+5cM5ixs2ddf9e827OqN\nTCtW7qMy92xvbxZ7e7PDPJblOeZQkWPd1ukNrI6EYAtiw65eFSfJuIKvp8ZV/eUYzFtjypLWhYJd\ngbDOmhYeWLsL2zujD5ZHKRTaAczVPs9xv9PZDuBuIUReCLEZwKtwhMSYoLM/h+U/frxmLamzEbmP\noq5TeGLjPvzTr57B+69/Cq/vjU7Du/EfW3Duz56oKtC6o2sQy3/yGB6KqC99pffsTd9+EG/69oPD\nPFZtLAU51u2dXkthcBS66K7f1YN3/fgx/PSh15wxuEWAPYMj4z6Sz1LU7qNqGfRYCuWf9+6BPC77\n/fN4ZEP0npIohcJzABYR0QIiSgK4GMDdvm3+DMdKABFNheNO2hThmKqiezAP0xbY15eryf6UpVBr\n91HEFc1rtnepf3cPRqfhtXcNoC9rVjV57e/LQQhHgEdBpZZCLY+VGWZMQY7VLxSyoyAUOtx356nX\n9wMoTIYjZSmYtoBpOVldY6m4U7/HlaQ7y2djJILlkR1BCGECuBzA/QBeAXCbEGItEV1LROe7m90P\nYD8RrQPwMIDPCyH2RzWmahms4ToF3713PR5/bR+AYvfRzu5BXHXbqiEfp1r30d2rd+BXj5eXvZm8\nhStufhH3aQVVww2C+tnWMYDP3b4aectGZ78zUfTnKtci5bbD1a6/c+8reG5LsXtMnm+ldQo3PPY6\n7h2iZSkn7WG7j5Sl4HU1BAlb2xb4yp9fwvNbo3ENphIxz7HlOfYMQ7nI5C1cdduqophJEJYtCseu\n4Lp2DeTw6VteHLbykzUtfO721Xhjf7C7R3/XK3F9yrGnxrNQAAAhxAohxKFCiEOEEN92v7tGCHG3\n+28hhLhKCLFYCHGUEOKWKMdTLbVcvOaXj76Ov63bDaDYXHx6037c+UI7tuyv3p8OFCyPSieTK25+\nEd/66ytlt3tlZw/uXr0DL7f3YGZL2j1GbbXNp17fjzue3472zkF0Djha5UC28mMMKKEw9InUtgWu\nf3QT3vfLp4r+VsgYq2z/Nz65Bf9bRRaKTs3cRyGWQpBQeGZzB/7w9Bv49xXrh3XM8LE4z7rMNqqF\npbBpbz/ufKEdT28qrz+atq1cVpUoTS9u68KfV+3Ay+3dFY8nKID/8Po9uOP57fjufcHvmX4vKklJ\nzR0oQmG8I2/ccJuh+TUB/8Opsk6GqIVXE1OoJiCrb7pkVjOA2q/ZICdb07bROVDeUtjXl/UI6f7s\n8LXrUr+t1lLoyZjqPIY6juEHmp2xtvuEQpBb6o7nHQF2+Iymqo/TlzXRXeZc5bnId0gFmocRU6hG\nEbBsoRpQ5iy7bAaWVEiqeeeDYgK7e5ykg0n1ycDfBFkKvZl8kYUin3epKKTi0devsFAogbxxww3Q\n+d1F/s+ZYboNqokpbK4iu0fXWI87qNX9rtaFd4WUzy5pKYS8kEIILPvWg/iX361U36kJYhj3aKCE\nEJLXoNKYQl/WHHJ8Q2UfDdNFJ5+vnd2DnmctaKJ78BXHeiWq/jinfO9hLL32gZLbyPsy4HuXhmMp\n9Ocqt+BNTSgIUT6oKxWSTBXWWpDCsLvHKZ6b1pQK/I1+L+Tv3/TtB7H0G97red7PnsD/PLFZvdvj\nOqZwICC1muEG/vxCwP9gZobpNshXUby2dkflZrEUAN+/6Gicd/Qs57saByule8G0BDrcyTSssElW\nqcrYjLPt8C0FOWkYseKZcSj9qqQbrBosW6hrMXz3kbMfWwC7tMpefRKVGrO81kN5xjsqEH7y+slr\nPFiDmMJAFWPWYwpAecVJ7rs6S6F4n9JSqEsEa/b6mGRKqv98hBDY1ZPBnp6M8gKwUBhlBqvQSErh\n1yT8D6ayFPI2Xt3dix8/+GpVhUbVBJrlYjFJo/ytlxrrklktSLsPd6bCyfePz2zFE9rkDTja9jfu\nWeuZqKT7qDebL5pAisa+wxm7rtVWG1O47+VdymUikdc/XkIoVJN91D2Yr7p/kX7vhh9oLvxer1Xw\nFkwJ2LZQCkot4mZByHOR5yeVijXbu/Gde18ZUkFdtZaCPsHLd+WGx17H81s7w/cdcA+e3dyBXzyy\nsfgYAZbCnl7nGQ97J3Vr0K8kymuSNW0I4fxfbs8xhVFmcMTcRwVf8n0v78KPH3ytKs1N7k++6KXY\n3uH4mSstmAGcDBKZRVKppXDdQxtxy3NveL5bta0Lv3lyC666bVVh7G7fJr3wK8xSkEJhSkPBJJcv\ncaXa9af+8Dw+d7u38lQKoUSAoBzKegq2qN49oo+/FjEFOXnI+w34cuMt4YlBDTdQH4b/vsgx7O/P\n4fpHNw2p4K+qmIIlPO5BOUn/5wOvBralkNtmAhSTK25+Ed+7b0ORC1ZPQpAT+k5X8Qmz3j2BZp+l\n0acsoYIVzJbCKDKYs5RWONTso6xpeX7jDwD7NYNCJas1pOrknFnYX7lgs3RtVCJA9DQ4OclUOnn0\n56wiwSYn3Z26peCOV58c/JaCDLRJ11d/1lQvnzT3K/HDh72g8nhxI8BSkIHmKlsRVOJa8RxHtxSG\nqITItb/zlo05rXWIkTctVZ+I8rY3b384lkJfqZhM3nsMv1tmKM3gpMswaMy2LdSkCrjZR9p2PZk8\nBnImsqYdqHzIfQcpgoe6wfj/9VmaevJGR38OpmWrIL+/c7EQAlv29aNdS6f1WxpvdAwgZ9qassiB\n5lHlwuuexHUPvw5g6IHmz92+xqMN+2+6v3hNtxTki1qNXzlfhcanZ8aUEyAFoWAod1OlQmEgZxa9\ntPLz/r6CAJBalsdS8E0yS7/xAM76yePYsNvpjz+Yt9SLX7AUyo9r097gIPtg3tlXPBZkKVSXfSSp\nNgNJnzyHorWv3NKBY679G7Z3DsC0BeqSBma21HnSUv0FU3mPIBq6pVAqA0k/l86BXJGikDerFwoD\nJWpTvn7PWhz5tfvVZ8vnPrr4hqfxpTtfAgCP8JD0+7R0nSkNTibRvS9761D0Z+PE7/wdP394o5oz\n/Of3lzU7cdoPHsENjxXqhPxW+zk/fQIX/fIfWm2HzYHm0WRH96AqihlqSmp75wC2aWa7X0PN+SYY\nVbSUt9QDVs3EoO+/nIXRpQVByx1DjiuViIGIkIrHKhJWjsUjil4smYHSkym8jEHuI71OwbIFsqaN\nTXv7sbsngzY3m0NuX2qC8LNuZ3CQfTDnXIdEkKWgtbMOIyjNt6vKYPNw3Ueb9/XDsgV2dGWQt2zE\nYzHMbvULBa9v3WMpDCO4XcpVpp9XR3+u6JkYSpVxwVIo/u3vntrq+axnHwHAvr4cXnbdkL2ZYqHg\nD4gHjdWfNqpb/nlLYNW2Lu2zd4wyK+kH71uK7190tPq9P2a1Znu3mneyps11CqOJaQl1I3UNvhqy\npu31Yxa5j3yWgtYILT9MS6HcS9bRn1MZEf4H9pZn31B+ezkeoPAgpuKxQI3y+a0duGtVoa3VQIgJ\nHiRclfuoL9hS0Av6Mnkbi2c69RJSKPSFTBA7uwdx/aOvewKZ8twaU4VlRO58YTv+8boTEPe7j4QQ\nFVkKQW6pjv4chBD45aOvV5QG7HEfDWGCloK2P2vCtAQSBmFOa53HfeQXCroWm807i/v89O+veSy5\nio5douZAP6+ugXzRM1EqY+4va3YEFqhVowj4s48AKKUvqB5GpaQGPOfSsvL/zT+h64I4LKnkgmNm\nqTRvyxZKYfJsq7mVD4g2F+OVvGUrP+BQLYWs5g8EqnMf+QVSJeiWRylLYTDnPFzTm1OB2379nrW4\n/flCt3P1ILquo1TCCBSQv35iC76jVcTKF8v/Muoam/R/SwEpYx2T6hMeS2GtJqQAYLFbRCeFiIop\n+CaIFS/twnfuXe/pW7WjK+M5JgB88y/r8MdnnIB4wuc+ylsCUqaUiikECeKugTye29KJ7967Ht+u\noHrcYykMwZUjUzx7syZM27EUZraksbs3qwSjPzc+ZzmfY+RMQI+9thc//NurFVW7e45dylLQzqV7\nMI9M3sKb5req70oJhctvehEX3/B00fd9VaSk+rOPgMJz2BdkKZSIV+S1eUFXNvxJCLog9p/fYN6C\nESMkjJjKdrNsEVjFr1sK/ncxSlgoaAjhpOgpjaCEKVmKrGl5LIXi7KPgQHMmb2m56lW4j7RtS71k\ncuKd1uy0rNCFgmk5gsyvsabijusIQKj7qKM/55kY5EunTwi2T2OTgTYZJJe/mVSX8Ghw6/xCwWcp\nhMUUBgJ8w3oPHCEEcqbt8f37LQX9XIOyj+TEoF/H5nQc8RihcyCHP73oBCTntNYV/da/n35tUhiK\n+0he/76MibwlEDcIrfVJWLZQVoS3M6etrn1TOoFM3lLPR6VV72k3I61UzYF+DQdyFgbzFo6d14rf\nfewEAENrIz8QkpIalDhh2XZoinNgTEEqNIFWrXD3KTzPg/966cLKH2gezNnKUpd1MaYtAq2Wfa7i\no6/dze6jEUb6BpW2bg5RKOS9D6Jfk8zb3nL7IEuhWveR9IeXshTkSz9dCgVtXAP54ok8m7c9D6Ej\nFIr33zmQw0CukDnl73MzkDNx8JdW4CcPvqZ+I7MzlPaVczSopnTCc+027PIKhUXTGxGPUXFMwR33\nC2904vCv3qvy8/V7J190Wdm6v9/rJjF8lkLWJzR1vnDHGiz44grPOQBAS30Ck+qT6BzI469rdrr7\nLV0u/N371uPDv35WO+4Q3EeuC6cvm4dp20gaMbS6LRZkfEOfrPKam7QpHUcmbysfe2O6slV6G5LO\ndj0BGrckk7eV8OjPms7neExlouUqCDT7axnCgsF7A9xeeUuoRAI/QUJBCZyAexAWgwnrizWpPlHs\nFTAtdT2MMpaCdENlTaftd9IoKGhRwkJBw99DSG+kVU0xkjT35G/87iMhvNpFIR/Z0oRCdYHmBtdP\nXup3sgvpjAD3kXwovbnrFlJaRWYqbgS6NrpcbVtqjCpY5/5fPtz7tJdWTlDSLTOYt5AwCPVJw5Mq\n2DmQ98QApjelMbUxVbAUsoVrBwCb9/Yjk7fVyl5BloKzvV2UI++/xx6h4PvbrSsdN1vO9Prmm9MJ\nNKQM9GTyarIsle4phNOML+y4laJbCqa0FBoSAArpsZ7iNa1OoTmdQNa0lFBoqlAoyILGcpbCZFc4\nyXGkkwaScWdyq8RS8E/2AyHWYdACNP7sI51M3i46fn+JimZ9W72OIcyymtKQLFIIMzlLXTddKEhL\n4ZsXLME3LzwSALDVjac584k1IlYCwELBgzQJ5Uuua1Z+zWFfXxa3POstzpJkfRZG0IOvm596RbNy\nH2kv8NOb9uMb96xVFcJ/W7cb63f14K5V7Xhj/wDyllBaWzWWgv5S9Qf0ECqyFBLF7iMhBDrc/erB\nTsC5ZkIIT062RAoD3X2UMGJoSMU9lkJf1sT8qfUAnOyglroE2ppShZiCr5BJWjwylqC/3J7akQCh\n4L9P+rUIm7z292c9L35zOoG6hFFxlpe/qrYuYQypTkFOzH1ZR7GIGzHVjE0KbX+dgtRipaWw371m\nsSq10dLZRzaa6xKIEZRlVpcwlKWgX9eXtnfjofVOLyZdQG/vHMTdq3dg6/5+3PTMGyr5wC9s/V1h\ngUL2UVC1OlBcKBnmmvKPdbDMs2HECJPqk4ExBek+kinQTtM+ZxxHzZmEE+ZPBuDUKwCF7KORCDID\nznKYjIt0EfgDzYAzudQnC5frL6t34Ov3rMPpi6djamOhwlbPWBnIWWhIxT0PBpFjKeRtG3VwHg69\nO2aQpfDzhzbiiY378HJ7N05aNNXTEK6lLoFkPKa0sVLZR10lYgrBlkJ599FgvrCild9SkCX6QS+r\nEsBasV5TKu5YCpp/tT9r4vAZrXi5vQdTG1OIxQjTmlLY2Z2BraUbFrpxOr+VVol+D8sJBf+187qP\nvNpgOhFDJu/sQ05wsyfV4aRFU/HAut3KKvMf188zviVOm+viQ7QUCu6jvCWQiJFyH0llQBdUpiXU\nc96UdiyK9i7X5VZhYoUU7OWyj1IJAw3JeMFSCBEK5/38CQDA5u+c7VHCtnUM4KrbVuPCY2Z72pL7\nA81B1dF508baHT2YN6U+sE6lN2Mq4SmEKJN9VOzyBYIz01rqEkgasaI6hUxesxRIiym4719D0sAU\ndz6Rae1Z9x1jS2EUKFgKMgNIm1D8gUzpL/f5AvWMFfly6VaBdIXovka9clEJBe2hky9Tb8Ys0tS7\nB/Ou+8h50HKmDdOyA3v1yKCq7NyoT4LyZfD24LE8FZSpeHH2kR6olRqjPqln8laIWe91HwFOxXND\nMu65pn0ZE9Oa0mhMxVWNgrQUPO4glSlWEMjO8b3anYy9ZE2raBLxv9z6ufob4rXUORPp3t6sumfX\nXrAE//r2hahLxDwTsHcC8d6bvb1Z5WMGXFfOMLKP+rImTNdS8LtttncO4qAp9Woc8hlsdt1FahKq\nMKYh3Sals48ct0d9ylDWm24pBAnA3T1ZzzVb767BvavHt5Kcb5xB+3ry9X1o7xrEB5bNDRyf91m1\nC+9uSJ1Ck/v+ettUFAuF5nQciXisONCsWQqGId1HhRT2+lQck+oSiMcIO7vl/XDc0SNlKbBQ0PB3\nG83kLUir0689yYf2j89uxdk/eVxrYlXsw/YEIt3J5PhvPaiKXPQVt4I6ZUpNry9rKhPfM26zEFNY\nu6MbC798LxZfc796qPT9SG1c/k4S1E/G0fJ8loLvZdHbREuNUZ/UM3mvpSD91X5XHQAk4oT6VCGm\nYNsCfTkTjek4pjenlNurrSmF/X1Z5QNvTsc195FXa/UI9rytrn/OtIt81WHuo3QiViRkg4SCnOjq\nEoZHWMp72d41iCVfux8Lv3wvNu7pVb+fNamQndRclyia7D5w/VP4wh1rUAo5MfdmTORtp06hKR1H\njBz3USZvYU9vFvOnNAAAPnrjc/iRG/iX90QK7zBL4ZZn38DCL61Q11TGWfZowjVv2Vj05RX43VNb\n3HN3NNyGZFzVP6QTMZVaGZTVtXZHt2fSlRloensUoDh1N0go/PnFdjSm4jh36azAc9LTUv3KjJ+c\naatrNZiz8KH/eQYfuP6pQPdRs7IUfDGFvI10UrqPnMnl31esxxf+16mybkgaiMUIUxtTaj0T6QJj\noTAKFAWa85YyLf0PiXxxV27pxLqdPeqB1DUcOdHK/X773UfiQycepP7+ituxVBWp5IPdR7pQCDSR\nLaHSHmV//JxlY6tvKcDuwbzzsLoPl8dSkO4jX+sDb0zBKIpZ6G2igyyFwbzlEQrNrqvC9F1rwJlU\nm9IJ9OVMxzWUtyAE0Jgy8IP3LcUXlh8OwBEKtoASei31CVUVWiy8vUK62Z3MgwLNRUFB5XNPFFkR\n8jz29mZVXEQKhXTC8Fkxzn62dQyo+yrdRnt7s2jT3I+6gJPjf2ZzB25duS103Qe930+/tBRiMcRc\nv3bnQE4VbC2Y2qDOXz5/8poEpa7q3PDYJpi2UM+Y5V6TNdu7lEB5eP0e5K1C8NwRCgbqU4bXfRQQ\naJZtJNbt6PHcRxlD2O0TCv44n8zQ0ekcyGNOa52yhvz0ajEFqcw0p+OB1yBv2epaZUwLj7+2D89s\n7gixFBJIxqn4mcpbSMe92Uc60kXd5luHoTeTH5G+RwALBQ8qJVX5py1MqncfAq053p9e3K5edOm7\n7sua2LinD09uLLSL9ruPzlg8HTPcZS0Bx+T399H3C4VMvtBYri9jerQySc6y0daYQkPS8BR7+bNC\negZNpcEAvpiCr0r0L2t2YE9vRvk/geKYwvbOAU9zMH9MAQD+9GI7Vmtl/1LTktdadx8ljRia03EI\n4bysUotrTCVw7LxWLJzWCABqEpXFaE2phLoOfqGweX8/Hlq/G5bt1CW0+ITC5IbCylhy4hdC4M8v\ntisXUFM6XpR2KKeBvX0FS0Fm1Og99JPxWCG1OVes/e7ty3omgIaUVyi86vZ7AoB7XyqslQ0Ad61q\nR28mj18/uVm5PfqyhewjAGitT6BzIKcE83zXfaTjzzYKKwo7xL3+t6907rlpC5x15AwIAdz5Qjse\n3rAHP39PVxaJAAAgAElEQVTYaS19zNxJAGQGWwz1ybiynsICzbI53rqdPR5hLsfe77u3eUt4JuSw\nDJ1kPFakZTe42nqQpTC1MYVM3kL3YB5/frFQqZ+3bKUM6NlHsnWFTnNdHAkjFhxoTnpjCv6xAkFC\nwWRLYTTwWwoZ01Z+Wak5PLJhDz5z62qs2e5MdNKd05818dO/v4bPam2Z/e6jRCzmabrWk8kX9bwx\nfdlHUhOfN7kepi0C/fOA8zDNnVwPPaXbnz/ek8mjOR0vWApmsKWwYVcvLr/pRWzZPxAQaC6M97O3\nrcafV+3w7F9eC8lP/+64KFpd4So1rUD3kREraK2DeaX9+vPm5QsjA6Py79m8XdQu4NdPbMYnfrtS\nCSzdfdQ5kMPBrubsjMm5Hpv29ePTt67C3e65BVkK8toFuY/0NN7W+oSa4KSwbK1PqHUt9vY6QuHT\npy9CYyqO6c1p7OgaVNdSL957aP0e9e839g/gyltW4Zq71qoKZCNGTvGabauxtNYn0dmfLwgF7Xwl\nMtAsCbMUpKb/zGan9YRlC8yf2oBj5k7CE6/tw+dvX401291Otlr9iOM+KlyThlRcq1Nwrp1tC3WP\nnt60X51/fdII1MRPPNjJ0PEnDwRNnEkjVmRBSOXMm/7snF9bUwp5y2n58elbVymLNG+JgvtIO648\nZwB45+HTALiWghELbHORdjX+WIxCV7zTrUfAebc40DwKyIkqZ9pKs2x1NUmp5ckXWwbN5MTVmzHR\nk8l7HuCBnE8oxGOepms9g6a3+tHUu6Q6/5cv4tzJjntoS0gfnYQRUy6kg9sa3P37LQWv+0gPgukx\nhdf2FLTTokCzNl79BWxKxwsxBZ9G99VzF+Mjb10AoBDUlO6jvMd9REoT68kUhEJTKlgoFCyFQo2G\n31LIWwK2AF7f69QtFCwFCznLVnEKwNF8hSgUEkkrsDkdL443uMIxLKYgmVSXVPdYXuPjD5qM9Tt7\n0Zc10Zd1AumfPv1QvPyNd+G8pbOQNW1V+LZuZw+aUnGcsXi6cvcAhaZseu3H9KaU0+bCEspfLd1H\n2zsHEI9RYHW1bimk4rHQbCnpbpP5/U47DcLBbQ3YuLcP+/py+OwZh+KkhVPVs1dwHxWO0daUKoop\n9OdM2AJ46yFT0DmQx4qXnPPX4y2SZ7/8Tpx15Ey1f4k/W06SjHuLvuIxUkJBL2CTgnOhsoicWhSZ\n0pvT3Ufae7DaVRCf+MLb8Y0LlgBwlJ9EPMBSyBUsBTmWIPyWQs9gni2F0UD3c8sXWGq4fq3fv+Ri\nX9YsykTyu48SBiGh3diX2rtx3Df/pj4HuY/kAzm31TH7N5UUCs42R8xwWkFIbeuO57fjmGsfQNdA\nHs3pBFJGIVOpMP6CpaBPPv46Bd2Pqz+4kxuSgZYCAExvTqG5zpkUZPaVctX5so/kdj2DBfdRQ4hQ\nkC+xnNSyZnG/fslre7xCQRadNfr2nbeEmvA7dPdRiKWwuzejek8poZAsXLOW+kLgWE62y+a3YjBv\n4Tk3rqBfx6VzWrBoWqNyW6zd0YMjZjbjyFkt2Ly/X13b3qxzrfXga0t90okp2AJxdyxTGpJYv6sX\n1z+2CbMm1QX6pXVLYeG0xkChIITA3t6smsR6M84kbsQIc1rrlfIyb0o9muviykqVLh1pKRA5z4pU\njuTzLrc/5+iZmNaUwi3POhPyTM3dKmlMxdVzWZGl4PtuUn0SM5rrQORVnLZ3DoIIOLit0TOmnsE8\nhBCu+8h5XgZypkpCed1NdY3HYur5kimp8jnZuKcXZ/zwUfRkTI9LNqwmpMh9lDVHpO8RwELBQyF3\nXqjOlktmtQAoPCDyJvvb7vZlzKL+JUHuI73pmt5i1yla0txHptd9JDW8sI6bcyfXq20OmlKPxlRB\nc//GPWvRNZDH7t4MmuuC3UcDWkqq7rLwZx/pflxpNfzy0uPRnE54Ygq6dt/WmFIWQH0qDiNGKpag\nu4+S8ZjPUnD255+46xIGiIDuQefaKPeRWew+ksgK50laTCFnOZPIf394GS45wUlZzFuFPjMdrjXY\nmIoXNcST22zvHFRau3xp03G/+8ibJrvM7Y756Kt7neujTQBEhCWzmrGrx6nDeGVnDxbPasbiWc0Q\nwknPBAq+cBl8/eSpB+Oco2aojJWEO2N97KQF+OQpB+PjJy3A185bHLiQkG4pLJjaEOg+6suaGMxb\nKlAtz9lvfcxprfc8CzKDTQZQJ9cnkTBiMFzXiRIK7vaT65M4ek6LUhr8QiFGzv1Xy8N6qtSDM3T8\nk+n3Lzoanzr1YMxtrcfr2vu0vXMAM5vTauKX83W3G/sToiBAuwfz8Hu14obTpuXHHzgG7zt+DpLx\nmLL8X27vUYqJnoIshezMljT++Ik3q++n+YSCEF63ZJSwUADwcns3bnxyswrqWbbAS+2On/BtC6cA\nKKRe+tdCkPTnzCK3ie4+MmKEWIwCe/YDhaIl+ZJs6xjEC290quPOnexYAUGFYIDTPVS+nM6LGVcv\nrpxohZBZEeExhaxpK383UOw+0n83mLdw5OxmLD9yBprr4nh4w168tL0b/TkTUxoLAdy2ppQyu+sT\nBuIxUsLP6z4qaFpOTMEZkz8QKtd2KLRlcCf6vK2K1/zIF7LZYyk4vvczFk/HomlNajzy/GRgsyEV\nD4wpTG9OQQjgZdenLDNqdPeA4z7yuh6PnN2ChEEFoeDzH9en4ujPmtjaMYCBnIXFM5tVd1h5b6QC\nIrNn/u0di1SmHABlKRw2owlfPPsIfOnsI/DOI6YXLTlK5BW6srrZj3QdzfcJBSMW8wiFua11aK5L\noCeTV00HU3FD1dFIAUjkdArNWTb29GTw8AYnXtJcl/Ccx8wWr/uoMRUHEamJ9Z7VO1X1szyWH7+g\nePvh07BoehMWz2zGKzt68PD6PejNOHGXOa31SuC88/DpAByFUCqMDak4iODpviuRE/yFx87GtOa0\nk5Lq/k7PctLdizIDadn8yXjbwqnqe3md9AylA8JSIKLlRLSBiDYS0dUBf/8IEe0lolXuf5+Icjxh\nXHPXy/j6Pevw3XsL7Z9Xb+tCYyqOg6c2ojEVVxp7WBuJ3oxZ5DaRE5Tsbw/A4z7SaXHz0+X+n9i4\nDx+/8TmVsSFdQ2HMakljyawW1CUMHD2nRb2YgPelb65LOAKKvBOyshQsG7t7Cn5qf6AZ8HZ1lQ/4\nQtfkvuz3K7FlX78SYoArFNyJvT5puFkZQUKBPOmRfQHjlySNmJoYG1MF91FYR8yNrsBXQsFtkS4n\nDHlfdPcRUMipL1ooybRx7FxH45c+ZT0lVTKpIaG6smbcQq50wsCiaU3YvK8fMQJmTfJqww1JA/1Z\nS1lsi2c1Y1ZLGg1JA5vc2IieNUPkCFtdeIYpH/724Akj5rFs0gkjcH1iKRRkYF5mZsVjpFybyXgM\nUxude53J22oiTMULloK8/gBUxe+PHnwN37tvg/P3dEK5bIHiayMVADn5/+jBV/Hoa45wlZbfx962\nwPObMF/84lnN2LSvHx+98Tn87KGNaO8cxJzWOsyf0oCGpIFPnnowAEdB0ddITseNwDUn4kbxtbVs\nx7LW5wZdaZCTvj8WIoXCJO166VZ7lER2FCIyAFwH4CwAiwFcQkSLAza9VQhxjPvfr6IaTymCesOs\n2taFxTOb3VzvhNomrAdOXzbcUshZtnoZ/S+lpCmd8BSvAU6O9f6+LBpTcc+LEvTCExHmTq7HK99c\njiNnu0LB1eb07B2pieumLVCc7jfV1fR1TUU+lFnNUpAT4NfPX4IfvG8pdnZn0DmQx0XHz1G/a0zF\n1WSQThqIG5r7SDvfhBFDk6uJ6dlH/piCM35DTYxNmvsoLEi6w3WzKPdR3onfJKWwjhV83Hrwsi4h\nx1tc7Tx/agNa6hLKpeMXCkQFK81ZeMlShYOHu+v9nryozaMZA06u+mDewkvt3YjHCIumN4LI7SDr\nWk+65tmYjCMWI9X/CggPYPrdRykj5nFn1PlqLCSy0M/vPjLcoG2MgDmT6hCLFQT7PleQ6DEFPQsp\nYRDylo2X2wvZO8118ZKWgrQ49AlS+uVlptM15y3GK9cuL5xjmFBw27ADTlC5vcsRCkfNacFLX38X\njnXTansy+ULasUGoSxqBa3D7r7lei6ELcV0Iy868/jHK1jkt9V4hOhJEeZQTAGwUQmwSQuQA3ALg\nggiPN2SCWui+ursPR8x0XtxWN4MDKCEUysQUEkojDX5ZTddn6X8h3+gYQGtDwjOxL3RdHZKpPvcD\n4ExGz2zuwAXXPel5mKTG7k+XG/BdA5n1oV8bqZ099upefPQ3z6I/a2oTIOHco2eiOR3H1MYU3rVk\nhvodEfncRzFs2tuPt333Ic/5Jg2n4KoxFUdPJu8E1wJyzJ2xxArZSe45ZfLhloJECsX+nFMYpywF\nLW9ez7Cqc8dr2QLPbNqP9//yKfRnTeQsZwLSJxZ5naX1lI4XfN+ynbr8m6yPOPuownWSyInvha2d\nWDitUV33+lShL5Q+yUihqT8jfq218L1/4oqp/c+dXId0wnDWFHGf81XbunDy9x5S6xovUJZCXu0v\nYcQws6UOs103kl7YB3gtBT0LKWHEMJCz1Nrb8rd67Yg/piCtQkLhPNa4Y9zTm1X3sxK3i3TJAYV2\nLfIcYjFC3IihMRXH7Su3492/eFKNuS5hYL8rFKZqblK/UJDHPf/nT3jOMR2QfeR3ezWk4mhIGqNi\nKUTZEG82gG3a5+0A3hyw3XuJ6BQArwL4jBBim38DIroMwGUAMG/evJoPNEgoAIWJsbUhWYgphLiP\n9vVlPTUCSSOmMmF095F/cfjjD2rFqYe2IWHEPEVekq0dA2itT6oCLcDJEJEZQl855wicsXh60e9k\nFs/qbV2Yp7lympWl4O1j5LcUZrXUYc32bk+zM6lRPrFxHx7esBdN6TgOn9Gs/d3A9y5aimScPC4U\nZ39pfPnsI3D2UTPxy0c34QmtyE8iJ2YnUGkinYgVpaNKZNAbAGY0O/dpT282UMutTxpKWEjNS95z\necxw95Gh7t1/Pfo6nt3SgTvdzKBkPIaDptTjKXfJSLmdzD6qSxrqmmVMy3G3uRPC/zntEDTXJfDu\nYwsWVWG8zjlv3t+Po2e3qO8bkoUOsro7QgqDxlT17qOkEUNLfQJfO28xzlg8XRXIZfJO19qH1u9B\ne+cgLjp+DuZNrlduQd1SAICvnnsEJje42q37jMnMqMZ0XPWk8loKMWzY3eN5p5rSXqtYKjzyHja6\nAmfZ/FYsXzID963dhR89+KoK+koLTJ+g5T3+n39e5rE6Z7ak8ZVzjsBph7XhjufbMZAzcfoR3nep\nOR33dPlNGDGkEjEl8CY3JFV8wV+hLAXUq7v71PohAFRFs/6boAn/2+8+CgkjhhduesHZZoQshdHu\nknoPgJuFEFki+iSA3wJ4h38jIcQNAG4AgGXLllW+sEEFWL6FvXXky9Zan8CWff14bktHaAdLf1Xj\npPqEx30khYE/i2X+lAZc8c5F+P1TWwL3u71jECceMsVj4i9y86jjMcInTj448HfNWpqh3rCsWflk\nY4HZR5KZri9XX6RcarlSq+rNmJ5xAcDyI4s1X8CxFv7lFGesQRkwQMGKkvEQyzZCF3zRrYd5U+ph\nxAiv7+mDEIVOtLIC+4iZzapFdaPrnur3CwX35Xxha6fSggFHKEite3qTc01ue87RW1LxmCdzSL7g\n0j2Qjhf89Y4VY6oJf0pjCle8c1HguUlLYV9f1uOD19ea8LiP3IlOjyn4lQ9JLMTF8VHXDy+12MG8\nhaZ0Aut29ODgtkZ876KlAArPkrIU3P0td+sGgIJCss1t/dycTmB/X797Dt6aiJfbvYso6S2/nX0l\nQOQoaBv39CklIWHE8Ll3HYr71nqrvGWGjiwM063Bd/omfKLC+3P1WYcHXq/muoRyPTrXy7EUZJLD\nlIYUgD7EY1S0AI5uoehKlx5TkD8JcnFdeOxsT/+yA6FOoR2A3ppwjvudQgixXwghIza/AnB8hOMJ\nJGgZPIl82Vrrk3ijYwDv++VTuHv1jsBt9eAs4GgQ/ar3kVA3dIqrTR3laoByUglLN8tZNlrrE54H\nTprwfm1cR59M9ElOvrBFMYVswd8NACce7GRdnX7ENPWdPJ7eAbSuTJrcaYe1FX3nz4Dxf9+cjqNn\nMI/N+/o9rgQd/SWqSxiY2ZLGq26GkWwZLXvp6C6euoSBpBFT7he/++j//e8a3Kytk1GXNNTEJ9cD\nkJlpfqEg75GcWNNJwxOHGfAVLoUhYwNOtlhhEtXXmtDdR00BlkKY4PXjd61ILVa60F7Z2eO5fnJs\nXYNSOy6+l1LxkJlyzXUJHDvP8c+/U3ue5DWPx0hVKAOF++fsn3BIW6OymKTA1H8fdj7yvg1nMm32\nVXsnDfI88zLLLuh6hz3n+u9lendYXyP9+5a6ROA2tSZKS+E5AIuIaAEcYXAxgA/qGxDRTCHETvfj\n+QCqWzG8BgQt3i3RhYIkbJUpf0+iqY0ppU2YVmG5zLamFF65djn+8fo+fPy3K9WkEpRhI2n1BSJV\n0LbEhBzW/li5j4wYcp71c0201icxkHNe5CNmNOOVa5d7LIG0shQKQiFdYpLb8K3lgf1dwoKg8oVu\nrkvg0Q17kbNsfPnsI4K31V70ZDyGua31eNUN+E5tTKKjP4fWhiR2dGewRPMd1yUNJ53V1bSTPvcR\nAOzUrL50orB0pL+BXipuKCGrU7AUDI+lMJi3iu5lELqLo8VvKciYgmYpyIla/12lQUn/xFWnWQpd\nAzm0dw3iw28pNHE0YoSGpIFun6WgI58xuSRqczqBw2Y0Yd217/JYCtJKaalL4A8ff7PqfSRXjJP8\n5d9OQkd/Dne+2I5GzY0aFDfR3TBGjDwK2VDwp0MnjJjnvQuK56ltQ46rj9tUQiF4W/37M5cEW+G1\nJjJLQQhhArgcwP1wJvvbhBBriehaIjrf3ewKIlpLRKsBXAHgI1GNJwz5cgVppEooaA9pWAWi3m4g\nYTgZS9LUzmvuI8B58eTLPhShIDUNvXLWT5CwI3IyVQDXUtD6zgzkLM95NqbjqEsaHgtFHrdLW0Am\nXaJzYypuBL64YUFQ+fI2pxPIubUdFx47O3TfkoThFFDtcidz+aLKe7pwWqMSyum44clcUpaCNrnp\nsSGZfQQUC/6kz1JQv0ka6v9yAvnIb57Dmu3dHmssDH0b3eLT15oIiimktDYqYdfYj3/C1IWYrInQ\nA7KAI3z8MQUdqV1LoSCfdV0gAJplWJdA3CgEvCfVeZ/3dKLwvjSmvPcdgOcZ9VoKsaLvqsUSXm+1\nXyhIazRooZ2w4+rt52UXhbAgsi4U9JYsURJpTEEIsQLACt9312j//iKAL0Y5hnIUfIPJojQz+bLp\nPs6glc2mNCRVNgIgNciECtLmLFGkNRw5uwUfP2kBTl3U5jlWEHKy/snFx6AhGVfae6kJ+crTF2F/\nX075XJfMasYFx8xSPmUnHdB5kGVwVhc+upkukcftDcm5rpTQIKj7Er33+Nnoz5pYNr81cNIFvJNZ\nIhbz1HGce/QsHD1nEvKWjcdf24dJ9UnMmlSHnd0ZxGLkyVzyB5r9pBOGCs7u7c2ipS5RqGCOx9DW\nWPyiKqGdKASa5bNVkftIryvR3Bd69lFQTIGI3Jqa/JDdR8pSyFkqgFqUAZSOo2sw3FJIJ5w0V9mb\nKsiaArzuQs+YAu5FQyqOz515qCerLWjS9VsKQLgWXgl+z0DCiHlqJ2QXZX/KMlDomit5x+HTsGha\nI5bNL7jKzDLuo7gRw1VnHOpxu0XNyEQuxhi9mbzqLy81riAzUL5s6TIP1TSfBE+57RqkpWBq+fCS\ndMLAV89drLJhKrEULjhmNk5fPF2zFMInmGlNaXz73Ueqz8sOasVlpxyiPktLYXdPRvl+daEQ9JAG\nHa9cTCGIIO0SKEwSbz1kKn75oeNDg+jO+GQswKkU16tq50+px9VnHa4yXZrr4pjTWqfG6hUKUkiG\nCwU5wZq2UCuXyf1MbSq2MJXQTsSKrmMl18trKWgxBTf7SAiBPq2Vsu7ikMpFWD2MH/95Sy14MG+p\nIrY6n4bflIqrOFXQvSQitDWlYNlOY76wc9bdhZVw+TsWYdH0Qjp2oPuoxjGFbp9QSMbJG6NKhr+3\nScN73gumNuCLZx/huWZWGfcRAFzxzkWq3c5IMCGFwnv/6x9463cfAlBwH00N0EjlRD07oLMkUHjB\nZ2uaQyoec4RCXRw5t5jK7z4KIkgoNKWLYxpA4cUtFVMAvBqn3/fflE5gZ88g3vzvf8dZP3nMPU7p\nlzPo5fZnH1VC2IQVZkEE4Q8QH6pNFtK6mNFSh6Z0HC11CSye2YwZrvBOai0y5H7C4hx1CcNz3np6\nb1LLv9fR74//+lTiPtKL0PyWgmU7a4D3Z011Pvp9lj73ii0F32Qkz1XGQIBipagxHVd9p8KOI1t3\nONlDYUqAm22WDn7uyj2P8vd6Z2L9fIwaCIXTfeneCSPmmaBLCXn/8xxUhCkthXLv8kgyIYXCq7v7\n1L/7NPeRH6l1LZnVgsc+//aiv0uftVxQBHD8fqmE4WnsFuQ+CjsW4LiJXvjqGcqPOsn3clQqFFLx\nmOrk6H94z1g8Xa3JK98pf2Wtn6DjDeVhDptIqnl5pZYpf3PUnBY88JlT8OBVpyht8v3L5uCRz52G\nVNzAZ888DLd98i0AnOvS7ws0hx27Lmlg0fRG9dlrKYRljMRAvsZthf2V99jWp3RLwRtTANyWKjlL\nCYVGj1BwflupgPVbCtJtOJCzVHW430JsSBa6xgZlHwEFwRy24pl+7CD30ktfPxNPXl2Une79fcCx\n9XuiLAVj6BPu5888DP/QxpEwYp7noZRS5F8HIqjmRsUURijdtBLGzkhGgUzeUr5ZvTJRoj9gcj0D\nHTlZ6z7C6c0p11KQjd3MQPeRH107rE/GMbkhqQSLPwiuAplltHSiQusD/+R0zlEzi7TWsPRPSdCD\nOxT3kd/sT/m0/kqQvmP9N4dOb/JUe8eNGKa4Gms6YShXXTIeU1qw3+Lwk47HsGCqLhQKi9SECRIi\nUtXMRdk9FVyvpBFTE5rHUnDv155ex1cv1wTwuI/ciaecZSrx31Np+fTndEvBO2ZP5XSZ9QBKuYak\nohRkKTSlE4FWmE4sRqEFYwBgGMO3FOJGzLOmgz/QXOp+9vqKYoPihlJujCWhMNrFa6NKTyavNMYp\nJVLLgEJnTr147ZyjZ+LEg6eoHGwA+PBb5jtrIbsPgOybUu4l1R9uZVbXhbiP4tJnXYF/OmWgN2sW\nPbwNqTiuPutwXHPXWvVdaxmhILtT6l00h2IpJHwvcl3Sqa6uRihI7W8omSX6mPVc+cBtk4bn3uhB\nV3nsn1x8jOoyK/nUqYfghAWTMa0phUtPnId9vU7QP2xVMx0iQn3SQE/G9MYU3An/b+ucNZLPWzoL\nqXgMb3FrSgCoit9S7qNvXngkJtcncfnNLwS4OJxr0++2yk7GY0UFb7oCExYfkgH4MNcQ4KzRAFQe\nUwgiYZBHI9cnV/nOVeOWLIe85z98/1Jk8nbJdtanHtqG9x0/B21NKfzikddLxg1Hqi12JUxsoTDo\nrHxVlzAC/X1+0glva4hj57biLYdM8Wxz3tJZAIAX3nAqaLfu70dvxizrPtLR2z2k4rEi8z1uOKmH\nlWidzgucDdz2w2+Zjy37BvDrJzcDgFp6tBR1CcMjFIaSfeSfsOoTBrqQr+rllZbCULRAfVKTvw91\nH7nXbWpjCvv6sp50STmGC44pTpu98vRCtfK3LjwKNz65Gfet3YWO/uLumoFjTDkL1egTibQUfvuP\nLZjRnMY7Dp9W1OKkUav4DeNDJzp1B5+/wwhMSSVyemFl83bgc1PJymHTmqWlEP5eyeeolIupHAnD\nq6TUOqbgR+7rPcc57Un0tUf8pBMGvv++pbhrlVOzWyrDcCxZCmNnJCOIfNB7Mnn0Zkw0pOJK+w7T\nfIBi/6H+ebZv2UCpIX3m1tXY2Z2pasKTL/SsSXWhQe62xlTJwhlJfUBXSR29OMofuwjCP0nUwn0k\nBWY1Wr8qOhuCFlgfUBVbKvsIAN5znDPxT9bcjNWM96g5jjWpB8RLjjFpoDEV91wrqbh0DuRx4bGz\nA59VGVMIm6x1pjWliqzDWIxQnzAc95HWwE8nqHePHxVoLmEpyN5gw7EU/Pcg6bEUhp+S6sf/vFWi\nFMnMONkmJYixJBQmpKXQkHLaA3e77Zmb0nFlvtUnjCJfoMQfWNTdEPd9+mRPlalfQ/Iv1VkK+eB9\n9sxD8alTDwnc5vb/81ZPB8UwpF82bPLWx1nOfQQUu4uGkn3kn7BM33KWlVAzS0G6j/xulKQzMcrr\n9oXlh+P9y+Z6hH81XSuPP6gVD151Cg7W4hMlx5iKozntfWb0cZ+woDXwdzL7qJJrefNlJ3qW4pTU\np+IYyJnImFbg/fV2+SwTaC7xjEpXWinBUY6iVuCettTDDzT78Vv8lTz/xx80GQ9edUpRd2OdseQ+\nGjviaQSRE+UdK7fjntU70JAylPZTH1C0JSm2FArbNqUTnt7v/gd95daOiscnX+imdEIFE/3MnlRX\nkcurQauuDUIfZ7kUQCBIKAzBUvBNJLIgsBoXW7KMhl8K/R4XKpq9+5GZWPL8jBipBd0lqSonm4XT\nmor886FjTBpFE6peULh4ZnDeunRRVJKSOrOlLtDPLRf5GcxZgfc3aOUwP1IolOrXI7ObSrmYyuG/\n/x5LoUxm2VAoKvar8PkvJRCAcWYpENF/Avi1EGJtuW3HC9I3+9eXnLZLZx81Uz380gcfhNzmrYdM\nwaT6RNGqUEHbOvufgfcEtEgOYygTXRiyf33Y5C0nHsMtMnrvcXNw4bGzQvfnFy5DcR8V8tPjOGZe\nK2ZPqsPNz75RXUxhCC4nia5xq/YXiRjec+xsdA3m8dD6PVg6twVHzGz2JBH4ibJr5flLZxet5Kdn\n41CMP/wAAB6BSURBVExvDnYdnrRwKs49emZFrsUw6pOOpZA17UBlwhuoD75n05vTePexs3HyoqmB\nfwdqYyn4738qwH1Uy/sUVuw3XMaVUIDTt+gGIooD+A2cVtfdZX4zptE17AuPmYX/e9pCbHCbqZUy\n42Rq3mEzmvC185ZUfLxf/FNlzV/jMWeFr1pmSyhLIUwoaMtkEhH+8/1LS+4vrVJBnTYZw6lTOGRa\nI373sRPUMqjVTPDSTTCUF15PxZW/JyL88APH4A9Pb8VD6/dgSkMK37zwyLBdDPnYlfLBNxevG6Jb\nCmEFYYfNaMLPP3jcsI7dkHIsBcsWga1UKrEUjBjhRx84puRxZMfXUgHYcvgtoqgDzf7zrdVkHlbz\nMhqUPSMhxK+EEG8D8GEA8wGsIaKbiKi4mmucoN9YuWhIQfN0/iYX69BRfuyIFrsYSr5+OepD6hQk\n0lJoqKCoCihMCM4C57FhuY/8weKqUlKHca10pcD/e+lOKfWyHz3Hcd2USkqIAnntl86JtuWBtBQG\n88GtvvV7Xmk9RBCy6DMorlEp/vsXaCnU4H3SW1vohAnnaqmlIjhcKpoJ3PWWD3f/2wdgNYCriOiT\nQoiLIxxfJOh5zTIzQD7ocSOGBz5zSmBHwmq100c+d1rJGEXR/t2sj0pbFFSC1C7DAmJqmcwKxymv\n07+cfDCOnTdpSBNjwldUVMgnr8ZSGLqA9lgKvt/Lv5UKIv/hE2/Gzq5M6N+jgoiw4oqTMU+rqo6C\nhpSB9i63cC0o0Kw3nRvGs/qTi4/Bln0DJfP3y1FKKNTSUrjlkydGes9rJVxqQSUxhR8BOBfAQwD+\nXQjxrPun/yCiDVEOLipMj1BwXjD5oMdjFJo2mA6ooi3F/KkN5TfSkA90QMPFIVM2+8g13Su1FKRQ\nmNKYxBEh2lM5/IuVx5WQGELvo2FmHxUVZilLIVxINqcTaJ4xMgue+PG3sY6C+mQcA1kTsVjxsqqA\n91mqJPW11HGGez5+DVvPNKplSupo3vORppKZYA2Arwgh+gP+dkKNxzMiWNqSmH5LoZRWUck2w+F7\nFx2N76xYr3K8a8GJB0/G2w9rC80CaUjGEaPKGrUB3rbQQ8XvLhqO+2hIlkIJq0hZCmMo8DfSyHTc\nsAJJ3aU00i40P/KZOWhKPea21quiOaCgfNTSHRvEuUfPVCspVss3LzwSD72yu8YjGh6VCIUufTsi\nmgTgNCHEn8drwFlfEEOmkap89QqK16J6yE5e1IaTryxevnI4HH/QZPzmo+GyOxYjNKUTFaW3Anpb\n6KELBRVTUAWDQ3EfSQFd/aRUyl3RUEFM4UBH1ikkjeCYUbpGlkItkM/M0jmT8NNLjvX8Le72Ropa\ncA0nsP+hEw9SFeZjhUqe/K/pk78QogvA16IbUvQEtdqNxQjJeKzkxCQzMco1txtvTGlMVlQIB9TG\nUlDuIvdaN6YM1VW0UoZlKZRwlakVvoYR/BzvNCQN5C3hKd7TqST7aKQoZWUaBkWWFHIgU4l6GHRV\nx3UltGULHDdvEq69wJtymC4jFIZTRTuW+dklx5Ztmy1Jq2K4oV8Df6D5vKWzMLe1vqKKaslwMrWC\nVpWTTG9O4/cfPwFv0jrfTjR0oRll9lEtkPc/yGKMu4oeUx2VTO4rieiHAK5zP/8rgOejG1L0OCto\nNeBInx9QX2UrCGkpRO2jHGmqWdVJXoPh5FX73Uf1yTjeujC8yCmI4QSay7VkPnlRbV144w1daAa5\n0TzZR6NuKYQrBwYLhSFRiVD4NwBfBXCr+/lvcATDuMWyReDDfNKiqVg6J7yCNepA83hg6dwWLJ3T\nErp2ciXEjeGnCqrFcYaZksoUU52lMLpCIV7CfXTcvFaIGmbyTRTKCgU36+jqERjLiGHaduDD/MP3\nl67AjDrQPB44/qDJuOvyk4a1D2kppIZxHYfjypvI968SdEshKKagX79KezlFRakeWJeeeBAuHWNB\n3PFAJXUKbQD+H4AlAFRFlxDiHRGOK1LCLIVyyBYYHLwaHrWwFGoR8GaC0es4xtLawUGomMIBlvwx\nmlTyVv4RwHoACwB8A8AWAM9FOKbIMW0xJLNXVdFOYPdRLfAHmodCUzqB6z90PN59bPECN8zwOGpO\nZQvTjwXKrYfBVE8lV3KKEOJ/AOSFEI8KIT4G4MRKdk5Ey4loAxFtJKJQFxQRvZeIBBEtq3Dcw8Ky\nROiC46WQWhM/gMPD3/toqLxryYyqMpaYyqhPxtWa5AJj2ymvUlJZUasZlVzJvPv/nUR0DhEdC6Bs\nH2i3X9J1AM4CsBjAJUS0OGC7JgBXAnim4lEPE9MWQ+ovtHBaI6Y3pzBvcrS9Zw50xsKLvHhmM95+\n2MTOMirFd99zNIDKV4obLdhSqD2VZB99i4haAHwWwM8ANAP4TAW/OwHARiHEJgAgolsAXABgnW+7\nbwL4DwCfr3TQw2WoMYVD2hrxzJdOj2BEEwujRpbCcFhx5cmjduzxwNsWTsWW754z2sMoC8cUak/J\nt9LV9hcJIbqFEC8LId4uhDheCHF3BfueDWCb9nm7+52+/+MAzBVC/LXMOC4jopVEtHLv3r0VHLo0\nYdlHzMhQi0AzwwClU1KZoVHySgohLADnR3FgIooB+CEcC6QkQogbhBDLhBDL2tqGZ/LbtoAtRr/o\nZiKT8HVJZZihMpxlWZlgKnEf/YOIfg6neE11ShVCvFDmd+0A5mqf57jfSZoAHAngEbeX+AwAdxPR\n+UKIlRWMa0hYbjULWwqjB1sKTK0YC/GpA41KhMJb3f9fq30nAJSrU3gOwCIiWgBHGFwM4INqB06T\nPdXbgIgeAfC5KAUCUGiGN5TsI6Y2zJ5Uh1Q8xgH7cczJi6bi8df2jfYwEOeYQs2ppKJ5SMtuCiFM\nIrocwP0ADAC/FkKsJaJrAaysMC5Rc+QCO2wpjB5zJ9djw7fOGu1hMMPg9x9/82gPAQC7j6Kgkorm\na4K+F0JcG/S9b5sVAFb4vgvb32nl9lcLLEtaCiwUGGa8k4hzoLnWVOI+0ldcS8NZmvOVaIYTPaa7\n6lot10FmGGZ0GMr63kxpKnEf/af+mYh+AOCuyEYUMYWYAgsFhhnvlFpPgRkaQxGv9QAOqfVARgqO\nKTDMgcOsSWkYMcK0pnT5jZmKqCSm8BKgGqAYANrgzUQaV1hKKLC5yTDjnaPnTMLqr51Zct1tpjoq\nuZLnav82AewWQpgRjSdylKXAMQWGOSBggVBbKlGXZwLoEEJsFUK0A6gjorGRjzYELDfQzDEFhmGY\nYioRCv8FoE/73O9+Ny7hmALDMEw4lQgFEqKw0qkQwkZlbqcxiWlxRTPDMEwYlcyMm4joCiJKuP9d\nCWBT1AOLCostBYZhmFAqEQqfgtP/qB1O++s3A7gsykFFicl1CgzDMKFUUry2B04zuwMCthQYhmHC\nKWspENFviWiS9rmViH4d7bCiw+TsI4ZhmFAqcR8dLYTokh+EEJ0Ajo1uSNFicZ0CwzBMKJUIhRgR\ntcoPRDQZ4zn7iNdTYBiGCaWSyf0/ATxFRLcDIAAXAfj3SEcVIbJ1NscUGIZhiqkk0Pw7IlqJwkpr\n7xFCrIt2WNHB2UcMwzDhVOQGcoXAOiJqAPAeIvq+EOKcaIcWDZx9xDAME04l2UdJInq36z7aCcdi\n+GXkI4sIzj5iGIYJJ9RSIKIzAVwC4EwADwP4HYA3CSE+OkJjiwRunc0wDBNOqZnxPgAHAzhJCHGp\nEOIeAPbIDCs6VEyBU1IZhmGKKBVTOA5OJfODRLQJwC1wFtkZ13BMgWEYJpxQS0EIsUoIcbUQ4hAA\nXwNwDIAEEd1LRNz7iGEY5gCkIse6EOIfQoh/AzAHwI8AnBjpqCLEshwPGFsKDMMwxVRVmeyupfCA\n+9+4hC0FhmGYcCJNwSGi5US0gYg2EtHVAX//FBG9RESriOgJIloc5XgAzj5iGIYpRWQzIxEZAK4D\ncBaAxQAuCZj0bxJCHCWEOAbA9wD8MKrxSNhSYBiGCadUncLkUj8UQnSU2fcJADYKITa5+7sFwAUA\nVIsMIUSPtn0DAIGI4ewjhmGYcErFFJ6HM0kHzZ4CTg1DKWYD2KZ9lqu2eSCifwVwFYAkCv2V/Ntc\nBne1t3nz5pU5bGlMW4AIiLFQYBiGKSJUKAghFozEAIQQ1wG4jog+COArAP45YJsbANwAAMuWLRuW\nNWHZNlsJDMMwIVTS+4iI6FIi+qr7eR4RnVDBvtsBzNU+z3G/C+MWABdWsN9hYdqC4wkMwzAhVBJo\n/gWAtwD4oPu5F04AuRzPAVhERAuIKAmnOvpufQMiWqR9PAfAaxXsd1jkTBsJgzOPGIZhgqikTuHN\nQojjiOhFwFmO053kSyKEMInocgD3w2mP8WshxFoiuhbASiHE3QAuJ6LTAeQBdCLAdVRr+jImmlLj\nduE4hmGYSKlkdsy76aUCAIioDRU2xhNCrACwwvfdNdq/r6x8qLWhL2uigYUCwzBMIJX4UX4K4E8A\nphHRtwE8gXG8HGdf1kRjmoUCwzBMEJUsx/lHInoewDvhpKdeKIR4JfKRRURf1kQjWwoMwzCBVFq8\ntgfAzfrfKiheG5P0ZUzMbEmP9jAYhmHGJJUWr82DEwgmAJMAvAFgROoYak1f1kRDki0FhmGYIEqt\np7BACHEwnOyh84QQU4UQUwCcC+DOkRpgrenLcEyBYRgmjEoCzW9ys4gAAEKIewGcGt2QokMIgb4c\np6QyDMOEUcnsuI+IvgLgD+7nfwKwP7ohRcdAzoIQYEuBYRgmhEoshUsAtMFJS/0TgGnud+OOvqwJ\nAGhMJUZ5JAzDMGOTSlJSOwBcSURNzkfRF/2woqE34wiFhpQxyiNhGIYZm1TSEO8ot8XFywDWEtHz\nRHRk9EOrPdJSaGL3EcMwTCCVuI+uB3CVEOIgIcRBAD4Lt431eKOf3UcMwzAlqUQoNAghHpYfhBCP\nwFklbdwh3Udc0cwwDBNMJbPjJncthd+7ny8FsCm6IUVHIdDMQoFhGCaISiyFj8HJPrrT/a/N/W7c\n0ZfJA+CUVIZhmDAqyT7qBHDFCIwlcqSlwNlHDMMwwZRqiHd32N8AQAhxfu2HEy1Z0wYRkIqzUGAY\nhgmilKXwFgDb4HRHfQZOM7xxjWkLJGK8FCfDMEwYpYTCDABnwKle/iCAvwK4WQixdiQGFgWWLcAy\ngWEYJpxSXVItIcR9Qoh/BnAigI0AHnHXXR6XmJZAnKUCwzBMKCUDzUSUAnAOHGthPgpLc45LbCFg\nxMa9F4xhGCYySgWafwfgSAArAHxDCPHyiI0qIkzbRpyFAsMwTCilLIVLAfQDuBLAFURqMiU4jfGa\nIx5bzXFiCiwUGIZhwggVCkKIA875btmCLQWGYZgSRDrxE9FyItpARBuJ6OqAv19FROuIaA0R/Z2I\nDopyPKbNMQWGYZhSRCYUiMgAcB2AswAsBnAJES32bfYigGVCiKMB3AHge1GNB3AsBRYKDMMw4URp\nKZwAYKMQYpMQIgfgFgAX6BsIIR4WQgy4H58GMCfC8bClwDAMU4YohcJsOBXRku3ud2F8HMC9QX8g\nosuIaCURrdy7d++QB2RzTIFhGKYkYyKYTESXAlgG4PtBfxdC3CCEWCaEWNbW1jbk4ziWwpg4ZYZh\nmDFJlD2k2wHM1T7Pcb/zQESnA/gygFOFENkIx+PGFKI8AsMwzPgmyinyOQCLiGgBESUBXAzA03mV\niI6Fs9zn+UKIPRGOBYAUCiwVGIZhwohshhRCmAAuB3A/gFcA3CaEWEtE1xKRbLv9fQCNAG4nolXl\n2nUPF65TYBiGKU2kS5AJIVbAaZOhf3eN9u/Tozy+H9O2YRALBYZhmDAmlC/FtsEpqQzDMCWYUELB\ntG3EDRYKDMMwYUwooWDZAjF2HzEMw4QyoYSCyYFmhmGYkkwoocC9jxiGYUoz4YQCxxQYhmHCmXBC\ngWMKDMMw4UwsoSA4psAwDFOKCSUUTIvbXDAMw5RiQs2Q3BCPYRimNBNqiuTW2QzDMKWZUDOkzTEF\nhmGYkkwooWBaNtcpMAzDlGBCCQUuXmMYhinNxBIK7D5iGIYpycQSCmwpMAzDlGRCCQWThQLDMExJ\nJoxQsG0BIXiRHYZhmFJMGKFgCQEAHFNgGIYpwcQRCrYjFGIsFBiGYUKZMELBtNlSYBiGKceEEQrS\nUuA2FwzDMOFMmBnSYkuBYRimLJEKBSJaTkQbiGgjEV0d8PdTiOgFIjKJ6KIox2LaNgCOKTAMw5Qi\nMqFARAaA6wCcBWAxgEuIaLFvszcAfATATVGNQ+LKBLYUGIZhShCPcN8nANgohNgEAER0C4ALAKyT\nGwghtrh/syMcB4CCpcB1CgzDMOFE6T6aDWCb9nm7+92ooALNvEYzwzBMKOMi0ExElxHRSiJauXfv\n3iHtQ6WkGiwUGIZhwohSKLQDmKt9nuN+VzVCiBuEEMuEEMva2tqGNBhbpaSyUGAYhgkjSqHwHIBF\nRLSAiJIALgZwd4THKwkXrzEMw5QnMqEghDABXA7gfgCvALhNCLGWiK4lovMBgIjeRETbAbwPwPVE\ntDaq8ag2FxxTYBiGCSXK7CMIIVYAWOH77hrt38/BcStFjsUxBYZhmLKMi0BzLTC5zQXDMExZJswM\nySmpDMMw5Zl4QoEDzQzDMKFMOKHAMQWGYZhwJoxQ4DYXDMMw5ZkwQoFjCgzDMOWZeEKBLQWGYZhQ\nJpxQ4JgCwzBMOBNGKJjsPmIYhinLhBEKtmD3EcMwTDkmjFAwLdkQb8KcMsMwTNVMmBlSNcSbMGfM\nMAxTPRNmiiy0zp4wp8wwDFM1E2aGtDimwDAMU5aJIxQsp6KZF9lhGIYJZ8IIBVPFFFgoMAzDhDFh\nhIJMSWVLgWEYJpwJIxTmT2nA2UfN4IpmhmGYEkS6HOdY4swlM3DmkhmjPQyGYZgxzYSxFBiGYZjy\nsFBgGIZhFCwUGIZhGAULBYZhGEbBQoFhGIZRRCoUiGg5EW0goo1EdHXA31NEdKv792eIaH6U42EY\nhmFKE5lQICIDwHUAzgKwGMAlRLTYt9nHAXQKIRYC+BGA/4hqPAzDMEx5orQUTgCwUQixSQiRA3DL\n/2/v3GPtqKo4/P2gtCDPUiw2FKVIVapIqYUWJCIiD4kJGghtg6ERIz7AYIyPNggppJriIygahQqU\nl5qqQKwxDRRQEKgtpbktrXChF2vk2oKtlJdteXT5x15zOh3PuXd67zn3zG3Xl0zOnj179vrN2nNm\nn9mzzxrgnEKZc4BbPf074DQpXo0WBEHQLlr557XDgH/m1p8DJjUqY2ZvSnoJGAFsyBeSdDFwsa++\nKqmzj5oOKdZdEaqoKzSVo4qaoJq6QlM5WqXpXWUKDYp/NJvZXGBuf+uRtMzMJjZBUlOpoq7QVI4q\naoJq6gpN5Wi3plYOH3UDh+fWR3te3TKShgAHAhtbqCkIgiDogVZ2Co8BYyWNkTQUmAosKJRZAEz3\n9HnAA2YezjQIgiAYcFo2fOTPCC4F7gH2BG42s9WSrgaWmdkC4CbgdklrgP+QOo5W0u8hqBZRRV2h\nqRxV1ATV1BWaytFWTYof5kEQBEFG/KM5CIIgqBGdQhAEQbAdM9stFuAsoBNYA8xoYr1rgSeADtKz\nEoCDgUXAM/453PMFXOcaVgITcvVM9/LPANNz+R/y+tf4vqpjoxv4N7Aqt99AayjaWA28CWzJbACz\nXGuHL2fnbMz0+juBM3trN2AMsMTz5wNDPX+Yr6/x7Ufk9pkD/BfY6u12WQV8dTjpPzyvu6++XxFf\nXeF6trivrupHXc3SewBpduJWb8cfef4twN9zvho/wOd6ZmMz8FAF/NTQRqlr2kBckNu9kB50dwFH\nAkOBFcC4JtW9FjikkPe9rPGAGcA1nj4bWOgn0mRgSe6Ee9Y/h3s6O+mWeln5vp+oY+N6/2KsaqOG\noo2/AhPc75mNWcDX6/hwnLfJMD/Ru7zNGrYb8Btgau74v+TpLwPXe3oqMD9nYzXpD5Rj/Pie9vx2\n+uoC4BEv/zHShWVcBXy1wo8vs7HEj6uvdTVL7405v210TbcA59Xx1UCd6wuBr5Em1bzYT5+3rF1L\nX9PadaEeyAU4Ebgntz4TmNmkutfy/51CJzDK06OATk/fAEwrlgOmATfk8m/wvFHAU7n8Wrk6NrrY\nsVNoh4bOwr5HAKtyNmZR/0K3Q3v4l+vERu1G+sJuAIYU2zfb19NDvJwa2HgIOL0Kvsrt8wowpWK+\nWuT6JzXJ783Quz/pTnQSjTuFgWq/S4D7SZ36q769Kn6q2Sh7TdtdninUC7lxWJPqNuBeSY97OA6A\nQ81snafXA4f2oqOn/Oca6C7aeHtBVzs09GYD4FJJKyXdLGl4HzWNADaZ2Zt16t8hdAqQhU4p1rUJ\nOJr0C7gSvvIowXv5dmizryTtKakD+CjwJOmHR3/93l+93a5pHakD7fJt33FfXStpWB991df2Ow/4\nJrCNNNw2rgJ+qmejFLtLp9BKTjazCaRosJdI+kh+o6Xu2lopoDcbVdDg/Bx4NzCe9KX+YSs1NULS\nfsBpwC1m9nJ+W7t85ZruJA1pvUYFfGVmb5nZeFIwy6OA9w20hjpsc02jgb1Jmmb65/GkIaFvtVJA\nof1GkoaMHm+lzYFkd+kUyoTc6BNm1u2fLwB3k6LDPi9pFIB/vtCLjp7yRzfQXbRRDKDVDg092jCz\n5/1Csw34BclXfdG0ETjIQ6MUNTUKndINHC5pL9LFdwNwV0V8dYRr+iVpTLkSvsrVNRJ4lDRE0d+6\nmqKXNEyzDZhsZusssRWY1w9f9aX99gJOkbSW1HkeTBrTr4Sf+hI+aHfpFMqE3NhpJO0raf8sDZxB\nGkPPh++YDvze0wuAC5WYDLzkt6T3AGdIGu7DBGeQxgfXAS9LmuwhxS8s1JW3saggrx0adrDh6X0y\nG9mXyvm0+yorP9VfujQGGEt64Fe33fyX2p9It+31bGea8qFTFvj+80hfmqFuowq+uoY0PPNohXx1\ngaSRbuM9pKG2J/vq9ybpfQD4vKenkWYgPZW7WAv4VMFXrW6/b/vxjAGudhvnttlP/QsfVPbhw2Bf\nSLMEniaNQV7epDqPJM0GWEGa2XK5548gPXh6BrgPONjzRXrxUBdp2tvEXF0XkaaQrQE+m8ufSDrJ\nu4Cfsn2KXN7Gel/eII0tfq4NGoo2niY9CDTgedd0u9tc6SfuqJyNy73+TnzGR0/t5r5f6lp/Cwzz\n/L19fY1vPzK3z1zXs8Xr6/D62+mrk13TVtLMo07X1G5fXeeasimpV/ajrmbpnQi8yPYpqdd6/gPu\nq1XAHcB+A3yuZzaeBf5SAT81tFFmiTAXQRAEQY3dZfgoCIIgKEF0CkEQBEGN6BSCIAiCGtEpBEEQ\nBDWiUwiCIAhqRKcQVBZJIyR1+LJeUndufWjJOuZJem8vZS6RdEGTND8sabykPSTNaEadubovkvSO\n3HqvxxYEO0tMSQ0GBZJmAa+a2Q8K+SKdx9vaIqyApIeBS0lz3TeY2UE7uf+eZvZWT3WbWUf/lQZB\nfeJOIRh0SDpK0ipJ1wPLgVGS5kpaJmm1pCtzZbNf7kMkbZI0R9IKSYsljfQysyV9NVd+jqSlkjol\nneT5+0q6Uyno2q/d1vgeZM4B9ve7mtu8juleb4ekn/ndRKZrtqQlwAmSrpL0WHaM/o/cKaQ4SPOz\nO6Xs2Lzuz0h6wvf5ruc1POYgaER0CsFgZRwptv5xluJPzTCzicCxwOmSxtXZ50DgQTM7FlhM+ldr\nPWRmJwDfALIO5ivAejP7IOmCf1wv+mYAr5jZeDO7UNIHSOEqTrIU0G0IKWRBpmu5mU0ys8XAj83s\neOAY33aWmc0n/QN7itf5ek2sNBqYDZzquj4s6ZM7ecxBAESnEAxeusxsWW59mqTlpDuHo0mdRpHN\nZrbQ04+TAtHV4646ZU4mBTzDzLKwJjvDx0lRPJcphX4+hRQFFdJb1+7OlT1N0lJS+JRTgPf3Uvck\nUnybDWb2BvArIIvWW/aYgwBIv1aCYDDyWpaQNBa4DDjBzDZJuoMU/6XI67n0WzQ+/7eWKLOzCLjZ\nzK7YITNFsdxsWSAd6W2kmDsTzKxb0mzqH0tZyh5zEABxpxDsGhxAeuHKyx4x88wW2HgEOB9A0jHU\nvxOpYf7yE20PbXwfcL6kQzx/hKR31tl1H1JI6A1KEXjPzW17hfTGsSJLgFO9zmxY6sGyBxYEeeJX\nQ7ArsBz4G2nGz7OkC3iz+Qlwm6QVbm8V6Y1WPXETsFLSMn+ucBVwn6Q9SBFtvwj8K7+DmW2UdKvX\n/w/SBT9jHnCjpM1sf2cAZvacpCuAP5PuSP5gZn/MdUhBUJqYkhoEJfAL7BAz2+LDVfcCY2376xCD\nYJcgfkkEQTn2A+73zkHAF6JDCHZF4k4hCIIgqBEPmoMgCIIa0SkEQRAENaJTCIIgCGpEpxAEQRDU\niE4hCIIgqPE/a/9KDR8tg+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x253ac824518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average testing accuracy is (take 3): 0.70\n",
      "Average testing accuracy is (Original): 0.48\n",
      "Average testing accuracy is (Monkey): 0.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwhile True :\\n    try:\\n        input_sequence = input(\">>> Please Input three events on PowerDirector15 : \")\\n        input_sequence = [\\'(\\'+input_sequence.split(\\' \\')[i]+\\')\\' for i in range(time_step)]\\n        #print (input_sequence)\\n        input_data = []\\n        for event in input_sequence:\\n            input_data.append(pattern_data.pattern_input_shape(pattern_data.index[event]))\\n        input_data=np.reshape(input_data,[1,time_step,len(pattern_data.index)])   \\n        prediction = sess.run (pred, feed_dict={x: input_data})\\n        print (\"Are you tring to do : \")\\n        for _ in range (3):\\n            print (pattern_data.getKeyByValue(pattern_data.index, np.argmax(prediction,1)[0]),\" \")\\n            prediction[0][np.argmax(prediction,1)[0]] = -10\\n    except:\\n        continue\\n    #print(input_data)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuration of batch size and time step in each process \n",
    "batch_size = 128\n",
    "time_step = 8\n",
    "\n",
    "# configuration of training arguments \n",
    "learning_rate = 0.001\n",
    "training_iter = pattern_data.howManyData(time_step) # event_sum\n",
    "display_step = 100\n",
    "n_hidden = 128\n",
    "n_classes = len(pattern_data.index)\n",
    "\n",
    "x = tf.placeholder('float', [None, time_step+1, len(pattern_data.index)], name = 'x')\n",
    "y = tf.placeholder('float',[None, len(pattern_data.index)], name = 'y')\n",
    "\n",
    "weights = {\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden, len(pattern_data.index)]), name = 'weights')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out':tf.Variable(tf.random_normal([len(pattern_data.index)]), name = 'biases')\n",
    "}\n",
    "\n",
    "# define lstm model \n",
    "def lstmModel(x, weights, biases):\n",
    "    x = tf.unstack(x, time_step+1, 1)\n",
    "    '''\n",
    "    lstm_cell1 = tf.nn.rnn_cell.LSTMCell(n_hidden, state_is_tuple=True, forget_bias=1)\n",
    "    lstm_dropout1 = tf.nn.rnn_cell.DropoutWrapper(lstm_cell1, output_keep_prob=0.5)\n",
    "    \n",
    "    lstm_cell2 = tf.nn.rnn_cell.LSTMCell(n_hidden, state_is_tuple=True, forget_bias=1)\n",
    "    lstm_dropout2 = tf.nn.rnn_cell.DropoutWrapper(lstm_cell2, output_keep_prob=0.5)\n",
    "    \n",
    "    lstm_cell3 = tf.nn.rnn_cell.LSTMCell(n_hidden, state_is_tuple=True, forget_bias=1)\n",
    "    lstm_dropout3 = tf.nn.rnn_cell.DropoutWrapper(lstm_cell3, output_keep_prob=0.5)\n",
    "    '''\n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0)\n",
    "    #lstm_layers = rnn.MultiRNNCell([tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(n_hidden, state_is_tuple=True, forget_bias=1),input_keep_prob=1.0, output_keep_prob=1.0) for _ in range(1)] )\n",
    "    #lstm_cell = rnn.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0),tf.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0)])\n",
    "    #cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * n_hidden, state_is_tuple=True)\n",
    "    outputs, states = rnn.static_rnn (lstm_cell, x, dtype=tf.float32)\n",
    "    #outputs, states = tf.nn.dynamic_rnn(lstm_layers, x, dtype=tf.float32) # outputs shape = [batch_size, time_steps, n_hidden] \n",
    "    print (tf.shape(biases['out']))\n",
    "    #pred = tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "    pred = tf.add(tf.matmul(outputs[-1], weights['out'], name= \"mulout\") , biases['out'], name=\"pred\")\n",
    "    return pred\n",
    "\n",
    "pred = lstmModel(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "'''\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "optimizer = optimizer.apply_gradients(capped_gvs)\n",
    "'''\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "x_axi = []\n",
    "y_axi = []\n",
    "\n",
    "# start session \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "#sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "sess.run(init)\n",
    "step = 0\n",
    "#saver.restore(sess, \"\\\\temp\\\\model_saver.ckpt\")\n",
    "max_acc = 0\n",
    "# training\n",
    "while step * batch_size < training_iter:\n",
    "    batch_x, batch_y = pattern_data.getTraining(batch_size,time_step)\n",
    "\n",
    "    sess.run(optimizer, feed_dict= {x: batch_x , y: batch_y})\n",
    "    if step % display_step ==0:\n",
    "        acc = sess.run(accuracy, feed_dict= {x: batch_x , y: batch_y})\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            print(\"Max accuracy updated : \")\n",
    "        y_axi.append(acc)\n",
    "        x_axi.append(step*batch_size)\n",
    "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print (\"Optimization Finished!\")\n",
    "plt.plot(x_axi,y_axi) \n",
    "plt.xlabel(\"Training Iteration \") \n",
    "plt.ylabel(\"Model Accuracy\") \n",
    "plt.title(\"Training Process\") \n",
    "plt.show() \n",
    "#save_path = saver.save(sess, \"\\\\temp\\\\model_saver.ckpt\")\n",
    "#tesing \n",
    "testing_times = 0\n",
    "testing_accu = 0 \n",
    "batch_size = 1\n",
    "testing_accu_original = 0\n",
    "# monkey accu\n",
    "testing_monkey = 0\n",
    "monkey = pattern_data.pattern_input_shape(pattern_data.index['(LIB_MEDIA_CATEGORY)'])\n",
    "for i in range(0, 10000):\n",
    "    test_data ,test_label = pattern_data.getTesting(1,time_step)\n",
    "    \n",
    "    if np.argmax(monkey,0) == np.argmax(test_label[0],0):\n",
    "        testing_monkey +=1\n",
    "    elif np.argmax(pattern_data.pattern_input_shape(pattern_data.index['(IMPORT_MEDIA)']),0) == np.argmax(test_label[0],0):\n",
    "        testing_monkey +=1\n",
    "    elif np.argmax(pattern_data.pattern_input_shape(pattern_data.index['(PREVIEW_SETTING)']),0) == np.argmax(test_label[0],0):\n",
    "        testing_monkey +=1\n",
    "    testing_accu_original += sess.run(accuracy, feed_dict={x: test_data, y: test_label})\n",
    "    prediction = sess.run (pred, feed_dict={x: test_data, y: test_label})\n",
    "\n",
    "    testing_times += 1\n",
    "    '''\n",
    "    print (\"Count Vector = \", test_data[0][0])\n",
    "    for _ in range (time_step):\n",
    "        print (\"Input_Event \",_+1,\": \", pattern_data.getKeyByValue(pattern_data.index,np.argmax(test_data[0][_+1])), \" \")\n",
    "    print (\"TrueValue :\", pattern_data.getKeyByValue(pattern_data.index, np.argmax(test_label,1)[0]))\n",
    "    '''\n",
    "    for _ in range (3):\n",
    "        if  np.argmax(prediction,1)[0] == np.argmax(test_label,1):   \n",
    "            testing_accu += 1\n",
    "        prediction[0][np.argmax(prediction,1)[0]] = -10\n",
    "    '''\n",
    "        print (\"   -->Predict \",_+1,\": \", pattern_data.getKeyByValue(pattern_data.index, np.argmax(prediction,1)[0]))\n",
    "        prediction[0][np.argmax(prediction,1)[0]] = -10\n",
    "    print(\" \")\n",
    "    '''\n",
    "print ('Average testing accuracy is (take 3):', \"{:.2f}\".format(testing_accu/testing_times))\n",
    "print ('Average testing accuracy is (Original):', \"{:.2f}\".format(testing_accu_original/testing_times))\n",
    "print ('Average testing accuracy is (Monkey):', \"{:.2f}\".format(testing_monkey/testing_times))\n",
    "\n",
    "#meta_graph_def = tf.train.export_meta_graph(filename='my-model1.meta')\n",
    "#Application\n",
    "'''\n",
    "while True :\n",
    "    try:\n",
    "        input_sequence = input(\">>> Please Input three events on PowerDirector15 : \")\n",
    "        input_sequence = ['('+input_sequence.split(' ')[i]+')' for i in range(time_step)]\n",
    "        #print (input_sequence)\n",
    "        input_data = []\n",
    "        for event in input_sequence:\n",
    "            input_data.append(pattern_data.pattern_input_shape(pattern_data.index[event]))\n",
    "        input_data=np.reshape(input_data,[1,time_step,len(pattern_data.index)])   \n",
    "        prediction = sess.run (pred, feed_dict={x: input_data})\n",
    "        print (\"Are you tring to do : \")\n",
    "        for _ in range (3):\n",
    "            print (pattern_data.getKeyByValue(pattern_data.index, np.argmax(prediction,1)[0]),\" \")\n",
    "            prediction[0][np.argmax(prediction,1)[0]] = -10\n",
    "    except:\n",
    "        continue\n",
    "    #print(input_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting trained model to PDR_event_model\\\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "export_path = 'PDR_event_model\\\\'\n",
    "print (\"Exporting trained model to\", export_path)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'PDR_event_model\\\\saved_model.pb'\n",
      "Done exporting!\n"
     ]
    }
   ],
   "source": [
    "# Build the signature_def_map.\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(x)\n",
    "\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "classification_signature = (\n",
    "  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "      inputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "              classification_inputs\n",
    "      },\n",
    "      outputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "              classification_outputs_classes,\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "              classification_outputs_scores\n",
    "      },\n",
    "      method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "prediction_signature = (\n",
    "  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "      inputs={'patterns': tensor_info_x},\n",
    "      outputs={'scores': tensor_info_y},\n",
    "      method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder.add_meta_graph_and_variables(\n",
    "  sess, [tf.saved_model.tag_constants.SERVING],\n",
    "  signature_def_map={\n",
    "      'predict_patterns':\n",
    "          prediction_signature,\n",
    "      tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "          classification_signature,\n",
    "  },\n",
    "  legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()\n",
    "\n",
    "print (\"Done exporting!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
